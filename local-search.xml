<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Reviews of SDN Topology Discovery</title>
    <link href="/2023/10/01/Reviews-of-SDN-Topology-Discovery/"/>
    <url>/2023/10/01/Reviews-of-SDN-Topology-Discovery/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>2023-10-05 weekly report</title>
    <link href="/2023/10/01/2023-10-05-weekly-report/"/>
    <url>/2023/10/01/2023-10-05-weekly-report/</url>
    
    <content type="html"><![CDATA[<h1 id="2023-10-05-Weekly-Report"><a href="#2023-10-05-Weekly-Report" class="headerlink" title="2023-10-05 Weekly Report"></a>2023-10-05 Weekly Report</h1><p><a href="https://python.org/"><img src="https://img.shields.io/badge/python-3.8-blue?logo=python" alt="Static Badge"></a><br><a href="https://scikit-learn.org/stable/"><img src="https://img.shields.io/badge/sklearn-1.3.0-blue?logo=sklearn" alt="SKLearnVersion"></a><br><a href="https://gplearn.readthedocs.io/en/stable/"><img src="https://img.shields.io/badge/gplearn-0.4.2-blue?logo=gplearn" alt="GPLearnVersion"></a><br><a href="https://www.usenix.org/conference/nsdi20/presentation/vermeulen"><img src="https://img.shields.io/badge/diamond_discovery-NSDI%2020-yellow?logo=NSDI" alt="DiamondDiscovery"></a></p><h2 id="Scheme"><a href="#Scheme" class="headerlink" title="Scheme"></a>Scheme</h2><h3 id="2023-10-01"><a href="#2023-10-01" class="headerlink" title="2023-10-01"></a>2023-10-01</h3><ul><li><input disabled="" type="checkbox"> 训练神经网络样本并进行符号回归<ul><li><input checked="" disabled="" type="checkbox"> 训练神经网络：生成数据集、使用MLPRegressor</li><li><input checked="" disabled="" type="checkbox"> 训练符号回归：获取数据、使用SymbolicRegressor</li><li><input disabled="" type="checkbox"> 将训练结果画出来</li></ul></li><li><input checked="" disabled="" type="checkbox"> 找云场景的论文和综述，发现可行的领域<ul><li><input checked="" disabled="" type="checkbox"> SDN Topology Discovery(There is a review)</li><li><input checked="" disabled="" type="checkbox"> Internet’s Diamond Discovery(Only for IPv4, no for IPv6)</li><li><input checked="" disabled="" type="checkbox"> Is there a diamond discovery for sdn layer?</li><li><input checked="" disabled="" type="checkbox"> No for cloud</li></ul></li><li><input disabled="" type="checkbox"> 搞清楚traceroute的底层原理<h3 id="2023-10-02"><a href="#2023-10-02" class="headerlink" title="2023-10-02"></a>2023-10-02</h3></li><li><input disabled="" type="checkbox"> 调研符号回归的评价方法</li><li><input disabled="" type="checkbox"> 联系CAIDA询问工具问题</li></ul><h2 id="python-sklearn-neural-network"><a href="#python-sklearn-neural-network" class="headerlink" title="python sklearn neural network"></a>python sklearn neural network</h2><h3 id="训练实例"><a href="#训练实例" class="headerlink" title="训练实例"></a>训练实例</h3><ol><li><p>Class MLPClassifier：实现了MLP算法</p><ol><li>代码：<code>class sklearn.neural_network.MLPClassifier(hidden_layer_sizes=(100, ), activation=’relu’, solver=’adam’, alpha=0.0001,  batch_size=’auto’, learning_rate=’constant’, learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True,  random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True,   early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10)[source] </code></li><li>参数：<ol><li>hidden_layer_sizes&#x3D;($i_1,i_2,…$)<blockquote><p>这个参数里$i_1$表示第一层有$i_1$个神经元，第二层有$i_2$个神经元，以此类推；</p></blockquote></li><li>activation <blockquote><p>激活函数{‘identity’, ‘logistic’, ‘tanh’, ‘relu’}, 默认relu </p><p>identity：$f(x) &#x3D; x$ </p><p>logistic：sigmod $f(x)&#x3D;\frac{1}{1+e^{-x}}$ </p><p>tanh：$f(x)&#x3D;\tanh(x)$ </p><p>relu：$f(x)&#x3D;\max(0, x)$</p></blockquote></li><li>solver<blockquote><p>默认的随机梯度优化器{‘lbfgs’, ‘sgd’, ‘adam’}，用于优化权重</p><p> lbfgs：quasi-Newton方法的优化器 </p><p>sgd：随机梯度下降 </p><p>adam： Kingma, Diederik, and Jimmy Ba提出的随机梯度下降</p><p>默认solver ‘adam’在相对较大的数据集上效果比较好（几千个样本或者更多），对小数据集来说，lbfgs收敛更快效果也更好。</p></blockquote></li></ol></li><li>方法<ol><li>fit（X，y）<blockquote><p>使模型适合数据矩阵X和目标y(label)</p></blockquote></li><li>score（X，y [，sample_weight]）<blockquote><p>返回给定测试数据和标签上的平均准确度 </p></blockquote><h3 id="数据生成"><a href="#数据生成" class="headerlink" title="数据生成"></a>数据生成</h3></li></ol></li><li>我们要创建的数据是$y&#x3D;x_0^2-x_1^2+x_1+1$因此是一个立体的曲面<figure class="highlight apache"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></div></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">x0</span> = np.arange(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>/<span class="hljs-number">10</span>.)<br><span class="hljs-attribute">x1</span> = np.arange(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>/<span class="hljs-number">10</span>.)<br><span class="hljs-attribute">x0</span>, x1 = np.meshgrid(x0, x1)<br><span class="hljs-attribute">y_truth</span> = x0**<span class="hljs-number">2</span> - x1**<span class="hljs-number">2</span> + x1 - <span class="hljs-number">1</span><br><br><span class="hljs-attribute">rng</span> = check_random_state(<span class="hljs-number">0</span>)<br><br><span class="hljs-comment"># Training samples</span><br><span class="hljs-attribute">X_train</span> = rng.uniform(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">100</span>).reshape(<span class="hljs-number">50</span>, <span class="hljs-number">2</span>)<br><span class="hljs-attribute">y_train</span> = X_train[:, <span class="hljs-number">0</span>]**<span class="hljs-number">2</span> - X_train[:, <span class="hljs-number">1</span>]**<span class="hljs-number">2</span> + X_train[:, <span class="hljs-number">1</span>] - <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure></li><li>numpy.arange(start, stop, step, dtype)<blockquote><p>start    起始值，默认为0</p><p>stop    终止值（不包含该数值）</p><p>step    步长，默认为1</p><p>dtype    返回ndarray的数据类型，如果没有提供，则会使用输入数据的类型</p><p><code>x0 = np.arange(-1, 1, 1/10.)</code><br>生成[-1, 1)内的数组，以0.1为步长</p><p><code>x1 = np.arange(-1, 1, 1/10.)</code><br>生成[-1, 1)内的数组，以0.1为步长</p></blockquote></li><li>check_random_state()<blockquote><p>是Scikit-learn（简称sklearn）中的一个函数，用于生成可重复的随机数生成器。</p><p>在机器学习任务中，需要使用随机数生成器来处理数据的随机采样、参数初始化、模型选择等方面。</p><p><code>rng = check_random_state(0)</code>以0作为种子生成了一个随机数生成器rng，类型是numpy.state.RandomState</p></blockquote></li><li>numpy.state.randomstate类型<ol><li>random.RandomState.uniform(low&#x3D;0.0, high&#x3D;1.0, size&#x3D;None)<blockquote><p>从均匀分布中抽取样本。样本均匀分布在半开区间[low, high)(包括低，但不包括高)。换句话说，给定区间内的任何值都同样可能被 uniform 绘制。</p><p>return: ndarray 或标量——从参数化均匀分布中抽取样本。</p></blockquote></li></ol></li><li>ndarray.reshape()<blockquote><p>reshape()是数组对象中的方法，用于改变数组的形状。</p><p><code>X_train = rng.uniform(-1, 1, 100).reshape(50, 2)</code></p><p>上面这行代码是利用随机数生成器从-1到1上按均匀分布抽取100个数形成一维数组，然后用reshape将一维数组变成一个二维数组，共50个元素，每个元素是一个包含两个元素的数组，其中第一个元素是$x_0$，第二个元素是$x_1$。</p><p><code>y_train = X_train[:, 0]**2 - X_train[:, 1]**2 + X_train[:, 1] - 1</code></p><p>上面这行代码我们算出了y值，其中数组的写法解释如下：</p><p>ndarray对象可以使用:来切片：<code>b = a[2:7:2]   # 从索引 2 开始到索引 7 停止(不包括索引7)，间隔为 2</code></p><p><code>X_train[:, 0]</code>由于这是一个二维数组，所以逗号之前是行切片，逗号之后是列切片，这个表示所有行的第一列。</p><p>关于ndarray的索引还有更高级的用法，请见其他博客</p></blockquote><h3 id="用神经网络训练一个回归模型来预测这个函数"><a href="#用神经网络训练一个回归模型来预测这个函数" class="headerlink" title="用神经网络训练一个回归模型来预测这个函数"></a>用神经网络训练一个回归模型来预测这个函数</h3></li><li><code>from sklearn.neural_network import MLPRegressor</code>MLPRegressor的参数与上文的MLPClassifier差不多.</li></ol><p><code>net = MLPRegressor(hidden_layer_sizes=(100,50), activation=&#39;relu&#39;,solver=&#39;adam&#39;, alpha=0.01,max_iter=200)</code></p><blockquote><p>第一个隐藏层有100个节点</p><p>第二层有50个</p><p>激活函数用relu</p><p>梯度下降方法用adam</p></blockquote><p>   <code>net.fit(X_train, y_train)</code></p><blockquote><p>训练即可</p></blockquote><ol start="2"><li><p>预测</p><p><code>y_net = net.predict(np.c_[x0.ravel(), x1.ravel()]).reshape(x0.shape)</code></p><ol><li>numpy.c_：将两个行数相等的矩阵按行拼接</li><li>numpy.r_：将两个列数相等的矩阵按列拼接</li><li>ndarray.ravel()：在不产生源数据副本的情况下将多维数组转化成一维（按行）<blockquote><p>用生成曲面的数据进行预测，好和原曲面进行对比</p></blockquote></li></ol></li></ol></li></ol><h3 id="画图"><a href="#画图" class="headerlink" title="画图"></a>画图</h3><ol><li><p>figure</p><p><code>fig = plt.figure(figsize=(12, 10))</code></p><blockquote><p>figure(num&#x3D;None, figsize&#x3D;None, dpi&#x3D;None, facecolor&#x3D;None, edgecolor&#x3D;None, frameon&#x3D;True)</p><p>num:图像编号或名称，数字为编号 ，字符串为名称</p><p>figsize:指定figure的宽和高，单位为英寸；</p><p>dpi参数指定绘图对象的分辨率，即每英寸多少个像素，缺省值为80</p><p>facecolor:背景颜色</p><p>edgecolor:边框颜色</p><p>frameon:是否显示边框</p></blockquote></li><li><p>画图</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">for</span> i, (y, title) in enumerate([(y_truth, <span class="hljs-string">&quot;Ground Truth&quot;</span>), (y_net, <span class="hljs-string">&quot;MLPRegressor&quot;</span>)]):<br>   <span class="hljs-attribute">ax</span> = fig.add_subplot(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, i+<span class="hljs-number">1</span>, projection=&#x27;<span class="hljs-number">3</span>d&#x27;)<br>   <span class="hljs-attribute">ax</span>.set_xlim(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>   <span class="hljs-attribute">ax</span>.set_ylim(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>   <span class="hljs-attribute">surf</span> = ax.plot_surface(x0, x1, y, rstride=<span class="hljs-number">1</span>, cstride=<span class="hljs-number">1</span>, color=&#x27;green&#x27;, alpha=<span class="hljs-number">0</span>.<span class="hljs-number">5</span>)<br>   <span class="hljs-attribute">points</span> = ax.scatter(X_train[:, <span class="hljs-number">0</span>], X_train[:, <span class="hljs-number">1</span>], y_train)<br>   <span class="hljs-attribute">plt</span>.title(title)<br></code></pre></td></tr></table></figure><ol><li>子图：就是在一张figure里面生成多张子图。</li></ol><blockquote><p>Matplotlib对象简介</p><p>FigureCanvas  画布</p><p>Figure        图</p><p>Axes          坐标轴(实际画图的地方)</p><p><code>fig.add_subplot(1, 2, i+1, projection=&#39;3d&#39;)</code>表示添加子图是1行两个第$i+1$个子图</p></blockquote></li><li><p>训练完成，结果如下：</p><img src="/2023/10/01/2023-10-05-weekly-report/result.png" class=""></li></ol><h2 id="python-gplearn"><a href="#python-gplearn" class="headerlink" title="python gplearn"></a>python gplearn</h2><h3 id="获取神经网络训练好的数据"><a href="#获取神经网络训练好的数据" class="headerlink" title="获取神经网络训练好的数据"></a>获取神经网络训练好的数据</h3><ol><li>导入<code>from gplearn.genetic import SymbolicRegressor</code></li><li>定义：<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs routeros">est_gp = SymbolicRegressor(<span class="hljs-attribute">population_size</span>=5000, <span class="hljs-attribute">generations</span>=20, <span class="hljs-attribute">stopping_criteria</span>=0.01,<br>                        <span class="hljs-attribute">p_crossover</span>=0.7, <span class="hljs-attribute">p_subtree_mutation</span>=0.1,<br>                        <span class="hljs-attribute">p_hoist_mutation</span>=0.05, <span class="hljs-attribute">p_point_mutation</span>=0.1,<br>                        <span class="hljs-attribute">max_samples</span>=0.9, <span class="hljs-attribute">verbose</span>=1,<br>                        <span class="hljs-attribute">parsimony_coefficient</span>=0.01, <span class="hljs-attribute">random_state</span>=0, function_set=(<span class="hljs-string">&#x27;add&#x27;</span>, <span class="hljs-string">&#x27;sub&#x27;</span>))<br></code></pre></td></tr></table></figure><blockquote><p>population_size : 整数，可选(默认值&#x3D;1000)种群规模(每一代个体数目即初始树的个数)</p><p>generations : 整数，可选(默认值&#x3D;20)要进化的代数</p><p>tournament_size : 整数，可选(默认值&#x3D;20)进化到下一代的个体数目(从每一代的所有公式中，tournament_size个公式会被随机选中，其中适应度最高的公式将被认定为生存竞争的胜利者，进入下一代。tournament_size的大小与进化论中的选择压力息息相关：tournament_size越小，选择压力越大，算法收敛的速度可能更快，但也有可能错过一些隐藏的优秀公式)</p><p>stopping_criteria : 浮点数，可选(默认值&#x3D;0.0)停止条件</p><p>stopping_criteria : 浮点数，可选(默认值&#x3D;0.0)停止条件</p><p>function_set : 字符串, 用于符号回归的函数，包括gplearn原始提供以及自定义，默认是(‘add’, ‘sub’, ‘div’, ‘mul’)</p><p>p_crossover : 浮点数, 可选 (默认值&#x3D;0.9)对胜者进行交叉的概率，用于合成新的树</p><p>p_subtree_mutation : 浮点数, 可选 (默认值&#x3D;0.01)控制胜者中进行子树变异的比例(优胜者的一棵子树将被另一棵完全随机的全新子树代替)所选值表示进行子树突变的部分</p><p>p_hoist_mutation : 浮点数, 可选 (默认值&#x3D;0.01) 控制进行hoist变异的比例，hoist变异是一种对抗公式树膨胀（bloating，即过于复杂）的方法：从优胜者公式树内随机选择一个子树A，再从A里随机选择一个子树B，然后把B提升到A原来的位置，用B替代A。hoist的含义即「升高、提起」</p><p>p_point_mutation : 浮点数, 可选 (默认值&#x3D;0.01)控制点进行突变的比例</p><p>max_samples : 浮点数, 可选 (默认值&#x3D;1.0)从样本中抽取的用于评估每个树(成员)的百分比</p><p>verbose : 整数，可选(默认值&#x3D;0) 日志显示</p><blockquote><p>verbose &#x3D; 0 为不在标准输出流输出日志信息</p><p>verbose &#x3D; 1 为输出进度条记录</p><p>verbose &#x3D; 2 为每个epoch输出一行记录</p></blockquote><p>random_state: 整数, RandomState实例 或者 None, 可选(默认值&#x3D;None)如果是int，则random_state是随机数生成器使用的种子；如果是random state实例，则random_state是随机数生成器；如果没有，则随机数生成器是使用的RandomState实例按“np.random”</p></blockquote><h3 id="使用神经网络生成的数据作为输入训练符号回归模型，然后生成公式"><a href="#使用神经网络生成的数据作为输入训练符号回归模型，然后生成公式" class="headerlink" title="使用神经网络生成的数据作为输入训练符号回归模型，然后生成公式"></a>使用神经网络生成的数据作为输入训练符号回归模型，然后生成公式</h3><blockquote><p><code>est_gp.fit(np.c_[x0.ravel(), x1.ravel()], y_sr)</code></p><p><code>print(est_gp)</code></p><p>out:<code>add(-0.986, X1)</code></p></blockquote></li></ol><h2 id="对符号回归的评价"><a href="#对符号回归的评价" class="headerlink" title="对符号回归的评价"></a>对符号回归的评价</h2><h2 id="Diamond-Miner-Comprehensive-Discovery-of-the-Internet’s-Topology-Diamonds"><a href="#Diamond-Miner-Comprehensive-Discovery-of-the-Internet’s-Topology-Diamonds" class="headerlink" title="Diamond-Miner: Comprehensive Discovery of the Internet’s Topology Diamonds"></a>Diamond-Miner: Comprehensive Discovery of the Internet’s Topology Diamonds</h2><h3 id="多路径路由（负载均衡）检测"><a href="#多路径路由（负载均衡）检测" class="headerlink" title="多路径路由（负载均衡）检测"></a>多路径路由（负载均衡）检测</h3><ol><li>多路径路由：<blockquote><p>[18] Brice Augustin, Timur Friedman, and Renata Teixeira. Measuring multipath routing in the Internet. IEEE&#x2F;ACM Transactions on Networking, 19(3):830–840, June 2011.</p><p>[29] Christian E Hopps. Analysis of an equal-cost multi-path algorithm. RFC 2992 (Informational), November 2000.</p><p>[45] Kevin Vermeulen, Stephen D Strowes, Olivier Four-maux, and Timur Friedman. Multilevel MDA-Lite Paris traceroute. In Proc. ACM IMC ’18. ACM, 2018.</p></blockquote></li><li>多路径路由检测<blockquote><p>[17] Brice Augustin, Timur Friedman, and Renata Teixeira. Multipath tracing with Paris traceroute. In Proc. E2EMON ’07, 2007.</p><p>多路径检测算法MDA——目前主流的检测算法[44]</p><p>[44] Darryl Veitch, Brice Augustin, Renata Teixeira, and Timur Friedman. Failure control in multipath route tracing. In Proc. IEEE Infocom ’09, 2009.</p></blockquote></li></ol><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1]. 【Python机器学习】用遗传算法实现符号回归——浅析gplearn <a href="https://zhuanlan.zhihu.com/p/31185882">https://zhuanlan.zhihu.com/p/31185882</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>Symbolic Regression</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Research of recent 3-year network directions</title>
    <link href="/2023/09/10/Research-of-recent-3-year-network-directions/"/>
    <url>/2023/09/10/Research-of-recent-3-year-network-directions/</url>
    
    <content type="html"><![CDATA[<h2 id="ACM-SIGCOMM-A"><a href="#ACM-SIGCOMM-A" class="headerlink" title="ACM SIGCOMM(A)"></a>ACM SIGCOMM(A)</h2><h3 id="2020"><a href="#2020" class="headerlink" title="2020"></a>2020</h3><ol><li><div class="code-wrapper"><pre><code class="hljs">VTrace: Automatic Diagnostic System for Persistent Packet Loss in Cloud-Scale Overlay Network：包级跟踪中记录和分析的现场转发情况</code></pre></div></li><li><div class="code-wrapper"><pre><code class="hljs">Switch Code Generation Using Program Synthesis：构造了一个编译器，用程序合成问题来写代码</code></pre></div></li><li><div class="code-wrapper"><pre><code class="hljs">Concurrent Entanglement Routing for Quantum Networks: Model and Designs：不同于以往在特定网络拓扑结构上分析传统路由技术的工作，本文提出了一种综合的量子网络与经典网络之间差异的纠缠路由模型，并利用量子网络的独特特性提出了一种新的纠缠路由算法。</code></pre></div></li><li><div class="code-wrapper"><pre><code class="hljs">Flow Event Telemetry on Programmable Data Plane：PDP上的流事件遥测</code></pre></div></li><li><div class="code-wrapper"><pre><code class="hljs">TEA: Enabling State-Intensive Network Functions on Programmable Switches：在本文中，我们探索了一种利用典型NFV集群中可用的服务器上的DRAM的新方法。</code></pre></div></li><li><div class="code-wrapper"><pre><code class="hljs">NetLock: Fast, Centralized Lock Management Using Programmable Switches：我们提出了NetLock，一种新的集中式锁管理器，它共同设计服务器和网络交换机，在不牺牲策略支持灵活性的情况下实现高性能。</code></pre></div></li><li><div class="code-wrapper"><pre><code class="hljs">Gallium: Automated Software Middlebox Offloading to Programmable Switches：我们设计并实现了Gallium，这是一个编译器，它将一个输入软件中间盒转换成两个部分——一个运行在可编程交换机上的P4程序和一个运行在常规中间盒服务器上的x86非卸载程序。</code></pre></div></li><li><div class="code-wrapper"><pre><code class="hljs">Mantis: Reactive Programmable Switches：在本文中，我们提出了螳螂，这是一个框架，在专门的反应控制平面架构的帮助下，在当今的可编程交换机上实现细粒度的反应行为。</code></pre></div></li></ol><h3 id="2021"><a href="#2021" class="headerlink" title="2021"></a>2021</h3><ol><li><div class="code-wrapper"><pre><code class="hljs">SwitchV: Automated SDN Switch Validation with P4 Models：</code></pre></div></li></ol><h2 id="ACM-MobiCom-A"><a href="#ACM-MobiCom-A" class="headerlink" title="ACM MobiCom(A)"></a>ACM MobiCom(A)</h2><h2 id="IEEE-INFOCOM-A"><a href="#IEEE-INFOCOM-A" class="headerlink" title="IEEE INFOCOM(A)"></a>IEEE INFOCOM(A)</h2><h2 id="USENIX-NSDI-A"><a href="#USENIX-NSDI-A" class="headerlink" title="USENIX NSDI(A)"></a>USENIX NSDI(A)</h2><h2 id="ACM-SenSys-B"><a href="#ACM-SenSys-B" class="headerlink" title="ACM SenSys(B)"></a>ACM SenSys(B)</h2><h2 id="ACM-CoNEXT-B"><a href="#ACM-CoNEXT-B" class="headerlink" title="ACM CoNEXT(B)"></a>ACM CoNEXT(B)</h2><h2 id="IEEE-SECON-B"><a href="#IEEE-SECON-B" class="headerlink" title="IEEE SECON(B)"></a>IEEE SECON(B)</h2><h2 id="IEEE-x2F-ACM-IPSN-B"><a href="#IEEE-x2F-ACM-IPSN-B" class="headerlink" title="IEEE&#x2F;ACM IPSN(B)"></a>IEEE&#x2F;ACM IPSN(B)</h2><h2 id="ACM-MobiSys-B"><a href="#ACM-MobiSys-B" class="headerlink" title="ACM MobiSys(B)"></a>ACM MobiSys(B)</h2><h2 id="IEEE-ICNP-B"><a href="#IEEE-ICNP-B" class="headerlink" title="IEEE ICNP(B)"></a>IEEE ICNP(B)</h2><h2 id="ACM-x2F-IEEE-MobiHoc-B"><a href="#ACM-x2F-IEEE-MobiHoc-B" class="headerlink" title="ACM&#x2F;IEEE MobiHoc(B)"></a>ACM&#x2F;IEEE MobiHoc(B)</h2><h2 id="ACM-NOSSDAV-B"><a href="#ACM-NOSSDAV-B" class="headerlink" title="ACM NOSSDAV(B)"></a>ACM NOSSDAV(B)</h2><h2 id="ACM-NOSSDAV-B-1"><a href="#ACM-NOSSDAV-B-1" class="headerlink" title="ACM NOSSDAV(B)"></a>ACM NOSSDAV(B)</h2><h2 id="IEEE-IWQos-B"><a href="#IEEE-IWQos-B" class="headerlink" title="IEEE IWQos(B)"></a>IEEE IWQos(B)</h2><h2 id="ACM-x2F-USENIX-IMC-B"><a href="#ACM-x2F-USENIX-IMC-B" class="headerlink" title="ACM&#x2F;USENIX IMC(B)"></a>ACM&#x2F;USENIX IMC(B)</h2>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Switch Tree</title>
    <link href="/2023/09/10/Switch-Tree/"/>
    <url>/2023/09/10/Switch-Tree/</url>
    
    <content type="html"><![CDATA[<h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><ol><li>SDN：Software Defined Network——数据面和控制面分离</li><li>Programmable switches:<ol><li>P4</li><li>match-action table: key-Source IP address, Destination IP address, or any other packet parameter, action: drop, forward, etc.</li></ol></li></ol>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Basic Things</title>
    <link href="/2023/09/10/Basic-Things/"/>
    <url>/2023/09/10/Basic-Things/</url>
    
    <content type="html"><![CDATA[<h2 id="Models"><a href="#Models" class="headerlink" title="Models"></a>Models</h2><ol><li>Long Short Term Memory(LSTM)</li><li>Stacked AutoEncoder</li><li>Ensemble Model：<ol><li>Bagging methods：Random Forest(RF)</li><li>Boosting methods：AdaBoost(ADB)、Gradient Boosting Decision Tree(GBDT)</li></ol></li><li>scikit-learn(a widely-used ML(merchine learning) framework)</li></ol><h2 id="Research-Direction"><a href="#Research-Direction" class="headerlink" title="Research Direction"></a>Research Direction</h2><ol><li>网络分类：<ol><li>流量大小预测</li><li>流量分类<ol><li>分布式流量分类：<ol><li>决策树分层给不同的交换机</li><li>决策树分支拆分给不同的交换机</li><li>In-Forest：交换机部署轻量基本模型，中心服务器分配模型</li></ol></li><li></li></ol></li><li>异常检测</li><li>网内分类：流量的生命周期是怎样的？</li></ol></li><li>模型翻译<ol><li>基于树的模型简化<ol><li>直接映射<ol><li>[14] J. H. Lee and K. Singh, “Switchtree: in-network computing and traffic analyses with random forests,” Neural Computing and Applications, pp. 1–12, 2020.</li><li>[18] C. Busse-Grawitz, R. Meier, A. Dietm¨uller, T. B¨uhler, and L. Vanbever, “pforest: In-network inference with random forests,” arXiv preprint arXiv:1909.05680, 2019.</li></ol></li><li>特征编码<ol><li>[19] Z. Xiong and N. Zilberman, “Do switches dream of machine learning? toward in-network classification,” in ACM Workshop on Hot Topics in Networks (HotNets), 2019, pp. 25–33.</li><li>[20] C. Zheng and N. Zilberman, “Planter: seeding trees within switches,” in ACM SIGCOMM Poster, 2021, pp. 12–14.</li><li>[22] G. Zhou, Z. Liu, C. Fu, Q. Li, and K. Xu, “An efficient design of intelligent network data plane,” in Usenix Security Symposium (USENIX Security), 2023, pp. 1–18.</li></ol></li></ol></li><li>神经网络到树模型的转化（Add.）</li></ol></li></ol><h2 id="Concepts"><a href="#Concepts" class="headerlink" title="Concepts"></a>Concepts</h2><ol><li>Programmable Data Plane(PDP)：P4 switch仅支持移位、加法、布尔运算</li><li>Rules of programmable switches</li></ol><h2 id="In-Forest"><a href="#In-Forest" class="headerlink" title="In-Forest"></a>In-Forest</h2><ol><li>交换机上不部署整个模型而是不是子模型然后集成</li><li>基本模型增强——精度：LEGO&gt;RF（随机森林）&gt;DT（决策树）<ol><li>RF是把每个DT的集中起来就直接得出结果</li><li>LEGO是把每个DT的集中起来之后重组，去掉冗余，添加能提升精度的分支<ol><li>首先利用流量特征去训练出决策树和随机森林，然后拆分路径</li><li>选出其中效果最好的k个</li><li>再把剩下的往里添加，设置优先级；如果不能提升精度就不用加了</li><li>优先级是该条路径分类正确的比例，比如它分类了10个内容，对了3个，优先级就是0.3</li><li>没搞懂增强模型多样性是什么</li></ol></li></ol></li><li>模型训练好了如何根据网络流量进行分类呢？<ol><li>首先根据已知的流量进行分配<ol><li>首先要考虑模型分配要考虑流量覆盖和分类精度<ol><li>流量覆盖用子网对的路径覆盖来衡量</li><li>分类精度用路径上的增强模型的多样性来衡量</li></ol></li><li>要求：<ol><li>对于每条路径，上面所有交换机部署的增强模型种类数量：<img src="/2023/09/10/Basic-Things/1.png" class=""></li><li>对于每个种类的增强模型，部署它的交换机数量：<img src="/2023/09/10/Basic-Things/2.png" class=""></li><li>交换机上部署的规则总数：<img src="/2023/09/10/Basic-Things/3.png" class=""></li><li>以上三个指标前两个越大越好，最后一个越小越好：<img src="/2023/09/10/Basic-Things/4.png" class=""></li><li>利用遗传算法解决该优化问题：</li></ol></li></ol></li><li>由于流量动态变化，静态分配完还需要动态调整<ol><li>用深度强化学习DRL来动态调整</li><li>将流量传输定义为马尔科夫决策过程MDP</li><li>Policy Gradient</li><li>Proximal Policy Optimization（PPO）</li></ol></li></ol></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>paper</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>The Importance of Vantage Points Distribution in Internet Topology Measurements</title>
    <link href="/2023/08/09/The-Importance-of-Vantage-Points-Distribution-in-Internet-Topology-Measurements/"/>
    <url>/2023/08/09/The-Importance-of-Vantage-Points-Distribution-in-Internet-Topology-Measurements/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Commonly Used Command</title>
    <link href="/2023/08/01/Commonly-Used-Command/"/>
    <url>/2023/08/01/Commonly-Used-Command/</url>
    
    <content type="html"><![CDATA[<h1 id="Commonly-Used-Command"><a href="#Commonly-Used-Command" class="headerlink" title="Commonly Used Command"></a>Commonly Used Command</h1><h2 id="远程连接服务器"><a href="#远程连接服务器" class="headerlink" title="远程连接服务器"></a>远程连接服务器</h2><ol><li>使用ssh远程连接服务器可以在本地操作服务器的命令行或编程：<ol><li>教程：<a href="http://192.168.17.1:25566/zh/%E6%9C%8D%E5%8A%A1%E5%99%A8/KDP%E9%9B%86%E7%BE%A4%E6%8E%A5%E5%85%A5%E6%89%8B%E5%86%8C%EF%BC%88%E4%B8%AD%EF%BC%89">http://192.168.17.1:25566/zh/%E6%9C%8D%E5%8A%A1%E5%99%A8/KDP%E9%9B%86%E7%BE%A4%E6%8E%A5%E5%85%A5%E6%89%8B%E5%86%8C%EF%BC%88%E4%B8%AD%EF%BC%89</a></li><li>Windows工具：x-shell</li><li>命令：在x-shell中可以手动连接服务器，也可以使用命令行连接：<ol><li>在x-shell中输入命令：ssh -p 55622 -i ~&#x2F;.ssh&#x2F;id_rsa ${USER_NAME}@166.111.121.63</li><li>其中55622是端口号，~&#x2F;.ssh&#x2F;id_rsa是本地私钥文件，USER_NAME是自己的用户名，166.111.121.63是服务器地址</li><li>以上几个参数顺序可以调换</li></ol></li><li>在vscode上连接服务器：<ol><li>教程：<a href="http://192.168.17.1:25566/zh/%E5%BC%80%E5%8F%91%E6%89%8B%E5%86%8C/vscode%E6%89%8B%E5%86%8C">http://192.168.17.1:25566/zh/%E5%BC%80%E5%8F%91%E6%89%8B%E5%86%8C/vscode%E6%89%8B%E5%86%8C</a></li><li>命令：<ol><li>k01：ssh guanzhongxu@<a href="mailto:&#103;&#117;&#97;&#x6e;&#x7a;&#x68;&#x6f;&#x6e;&#x67;&#x78;&#x75;&#64;&#49;&#57;&#x32;&#x2e;&#49;&#54;&#56;&#x2e;&#x31;&#55;&#x2e;&#x31;">&#103;&#117;&#97;&#x6e;&#x7a;&#x68;&#x6f;&#x6e;&#x67;&#x78;&#x75;&#64;&#49;&#57;&#x32;&#x2e;&#49;&#54;&#56;&#x2e;&#x31;&#55;&#x2e;&#x31;</a>@166.111.121.63 -p 55622 -i ~&#x2F;.ssh&#x2F;id_rsa</li><li>CD2：ssh guanzhongxu@<a href="mailto:&#103;&#117;&#97;&#110;&#122;&#104;&#111;&#x6e;&#x67;&#x78;&#117;&#x40;&#52;&#55;&#x2e;&#49;&#48;&#x38;&#x2e;&#49;&#x33;&#55;&#x2e;&#x31;&#50;&#x38;">&#103;&#117;&#97;&#110;&#122;&#104;&#111;&#x6e;&#x67;&#x78;&#117;&#x40;&#52;&#55;&#x2e;&#49;&#48;&#x38;&#x2e;&#49;&#x33;&#55;&#x2e;&#x31;&#50;&#x38;</a>@166.111.121.63 -p 55622 -i ~&#x2F;.ssh&#x2F;id_rsa</li></ol></li></ol></li></ol></li></ol><h2 id="Gitlab使用教程"><a href="#Gitlab使用教程" class="headerlink" title="Gitlab使用教程"></a>Gitlab使用教程</h2><ol><li>首先在网站上拉取代码<img src="/2023/08/01/Commonly-Used-Command/image_01.png" class=""></li><li>在本地写完代码之后，切换到分支：<blockquote><p>git checkout guanzhongxu</p></blockquote></li><li>添加、提交、push<blockquote><p>git remote add <a href="http://192.168.17.1:53210/ki3-jobs/jobs">http://192.168.17.1:53210/ki3-jobs/jobs</a><br>git add .<br>git commit -m “…”<br>git push origin guanzhongxu</p></blockquote></li></ol>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Tools Set for IP Topology</title>
    <link href="/2023/07/24/Tools-Set-for-IP-Topology/"/>
    <url>/2023/07/24/Tools-Set-for-IP-Topology/</url>
    
    <content type="html"><![CDATA[<h1 id="Tools-Set-for-IP-Topology"><a href="#Tools-Set-for-IP-Topology" class="headerlink" title="Tools Set for IP Topology"></a>Tools Set for IP Topology</h1><ol><li>pybgpstream安装：<a href="https://bgpstream.caida.org/docs/install/pybgpstream">https://bgpstream.caida.org/docs/install/pybgpstream</a><img src="/2023/07/24/Tools-Set-for-IP-Topology/pybgpstream.png" class=""></li><li>别名解析：<ol><li>kapar：<a href="https://www.caida.org/catalog/software/kapar/#H2513">https://www.caida.org/catalog/software/kapar/#H2513</a></li><li>MIDAR：<a href="https://www.caida.org/catalog/software/midar/#H2752">https://www.caida.org/catalog/software/midar/#H2752</a></li><li>iffinder：<a href="https://www.caida.org/catalog/software/iffinder/">https://www.caida.org/catalog/software/iffinder/</a></li></ol></li><li>scamper：<a href="https://www.caida.org/catalog/software/scamper/">https://www.caida.org/catalog/software/scamper/</a></li></ol>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Algorithm Complexity</title>
    <link href="/2023/07/24/Algorithm-Complexity/"/>
    <url>/2023/07/24/Algorithm-Complexity/</url>
    
    <content type="html"><![CDATA[<h2 id="指令复杂度"><a href="#指令复杂度" class="headerlink" title="指令复杂度"></a>指令复杂度</h2><ol><li>概念：指令复杂度分析实现算法的某个具体程序生成的指令数量、类型及 是否可以同时执行等。</li><li>一个是周期内多发射、流水线</li></ol>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Route Views</title>
    <link href="/2023/07/23/Route-Views/"/>
    <url>/2023/07/23/Route-Views/</url>
    
    <content type="html"><![CDATA[<h1 id="Route-Views-Project"><a href="#Route-Views-Project" class="headerlink" title="Route Views Project"></a>Route Views Project</h1><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><ol><li>University of Oregon([ˈɒrɪɡən]) RouteViews Project</li><li>CAIDA开发了工具BGPStream来下载和分析Route Views和RIPE RIS的BGP数据<ol><li>BGPStream框架：<img src="/2023/07/23/Route-Views/BGPStream_Infrustructure.png" class=""></li><li>三层概念：<ol><li>记录处理：使用 libBGPStream 处理 BGP 数据的组件。例如 BGPReader、PyBGPStream。<ol><li>BGPReader, a command-line tool to output BGP data in ASCII format</li><li>PyBGPStream, Python bindings to the libBGPStream API</li><li>libBGPStream提供了C++API</li></ol></li><li>记录提取和打包：BGPStream框架的核心，由libBGPStream实现。</li><li>数据访问：提供对不同 BGP 数据源的访问的组件。</li></ol></li><li>数据访问：BGPStream提供了四种数据接口来访问数据：<ol><li>BGPStream Broker（代理）：BGPStream Broker 是一种 Web 服务，它提供统一的查询接口来检索来自不同公共 数据提供商 （即 Route Views、RIPE RIS）的数据流，以及实时流资源（如 RIS-Live 和 RouteViews BMP 流）。代理接口支持 BGPStream 的几个关键功能：<ol><li>对路线视图和 RIPE RIS 数据的开箱即用访问。</li><li>数据归档镜像之间的负载平衡。</li><li>支持实时数据处理。</li><li>该方法获取数据见paper：BGPStream: A Software Framework for Live and Historical BGP Data Analysis<h2 id="BGPStream-A-Software-Framework-for-Live-and-Historical-BGP-Data-Analysis"><a href="#BGPStream-A-Software-Framework-for-Live-and-Historical-BGP-Data-Analysis" class="headerlink" title="BGPStream: A Software Framework for Live and Historical BGP Data Analysis"></a>BGPStream: A Software Framework for Live and Historical BGP Data Analysis</h2></li></ol></li></ol></li></ol></li><li>RIB：BGP路由器在路由信息库（RIB）[52]中维护AS间的可达性信息，其结构分为三个集合：<ol><li>Adj-RIBs-In：从邻居的入站更新消息中获知的路由。</li><li>Loc-RIB：通过应用本地策略从Adj-RIB-In中选择的路由（例如，最短路径、与邻居的对等关系）;路由器将在其路由表中安装这些路由以确定将分组转发到何处。</li><li>Adj-RIBs-Out：从Loc-RIB中选择的路由，路由器将向其邻居通告该路由;对于每个邻居路由器基于本地策略创建特定的Adj-RIB-Out（例如，对等关系）。</li><li>[52] Y. Rekhter, T. Li, and S. Hares. A Border Gateway Protocol 4 (BGP-4). RFC 4271 (Draft Standard), Jan. 2006. Updated by RFCs 6286, 6608, 6793, 7606, 7607.</li></ol></li><li>在BGPStream网站[12]上，我们提供了使用BGPStream API的示例代码教程。<ol><li>[12] CAIDA. BGPStream. <a href="https://bgpstream.caida.org/">https://bgpstream.caida.org/</a>, 2016.</li></ol></li><li>BGP collection process:<ol><li>BGP collector和一个vantage point（VP——探测点，BGP中就是提供BGP信息的路由器）建立链接并获取Adj-RIBS-Out（路由器通过本地的update message通告给特定peer的路由信息）数据的映像；</li><li>BGP collector以不同的周期存储：<ol><li>所有的VP Adj-RIB-out表格——RIB dump（转储）——所有VP发出的update message</li><li>该时间段内所有VP接收的update messages——updates dump——所有VP接收的update message</li></ol></li></ol></li><li>BGPstream Broker：meta data提供者——由于Route Views和RIPE RIS的数据是以文件形式存储的，爬取太过麻烦，所以由BGPStream Broker进行定期爬取并存入数据库以供查询</li></ol><h2 id="BGPStream-Installing"><a href="#BGPStream-Installing" class="headerlink" title="BGPStream Installing"></a>BGPStream Installing</h2><p>BGPStream框架由libBGPStream和PyBGPStream组成，其中前者是C库，后者是Python包，这里只关注后者；</p><ol><li>Installing PyBGPStream：<a href="https://bgpstream.caida.org/docs/install/pybgpstream">https://bgpstream.caida.org/docs/install/pybgpstream</a><ol><li>下载pybgpstream时报错</li></ol></li><li>PyBGPStream Tutorial：<a href="https://bgpstream.caida.org/docs/tutorials/pybgpstream">https://bgpstream.caida.org/docs/tutorials/pybgpstream</a><ol><li>BGPStream实例化：在创建 BGPStream 实例的过程中，我们还添加了一些过滤器来缩小流的范围。<img src="/2023/07/23/Route-Views/BGPStream_Intialize.png" class=""><ol><li>from_time并until_time指定流的开始和结束时间</li><li>collectors缩小流范围以获取来自指定收集器的记录，收集器见<a href="https://bgpstream.caida.org/data">https://bgpstream.caida.org/data</a></li><li>record_type&#x3D;”updates”表明我们只需要更新（即不需要 RIB 转储）</li><li>filter字符串指定更灵活和更强大的过滤条件，详细内容见<a href="https://github.com/CAIDA/libbgpstream/blob/master/FILTERING">https://github.com/CAIDA/libbgpstream/blob/master/FILTERING</a></li></ol></li><li>此时我们可以启动流，并重复请求新的 BGP 元素。每次读取有效记录时，我们都会从中提取它包含的 elem 并打印记录和 elem 字段。如果发现无效记录，我们不会尝试提取元素。<img src="/2023/07/23/Route-Views/stream_loading.png" class=""></li></ol></li><li>例子<ol><li>数据实例：(RIB dump or updates dump)update|(type)A|(time)1499385779.000000|(project)routeviews|(collector)route-views.eqix|(router)None|()None|(peer_asn)11666|(peer_address)206.126.236.24| (prefix)210.180.224.0&#x2F;19|(next_hop)206.126.236.24|(as_path)11666 3356 3786|(communities)11666:1000 3356:666 11666:1002 3356:86 3356:22 3356:3 3356:575 3786:0 3356:2003|None|None</li><li>BGPStream、BGPRecord、BGPElem三个类的用法、属性见：  <ol><li><a href="https://bgpstream.caida.org/docs/api/pybgpstream/_pybgpstream.html">https://bgpstream.caida.org/docs/api/pybgpstream/_pybgpstream.html</a></li><li><a href="https://bgpstream.caida.org/docs/tutorials/pybgpstream">https://bgpstream.caida.org/docs/tutorials/pybgpstream</a></li><li>“BGPStream: A Software Framework for Live and<br>Historical BGP Data Analysis”中的代码部分</li></ol></li></ol></li></ol>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Topology Datasets</title>
    <link href="/2023/07/19/Topology-Datasets/"/>
    <url>/2023/07/19/Topology-Datasets/</url>
    
    <content type="html"><![CDATA[<h2 id="Topology-Datasets"><a href="#Topology-Datasets" class="headerlink" title="Topology Datasets"></a>Topology Datasets</h2><h3 id="主动测量数据"><a href="#主动测量数据" class="headerlink" title="主动测量数据"></a>主动测量数据</h3><ol><li>The IPv4 Routed &#x2F;24 Topology Dataset<ol><li>Introduction：<a href="https://www.caida.org/catalog/datasets/ipv4_routed_24_topology_dataset/">https://www.caida.org/catalog/datasets/ipv4_routed_24_topology_dataset/</a></li><li>ICMP-Pairs实现：<a href="https://paris-traceroute.net/download/">https://paris-traceroute.net/download/</a></li><li>scamper中的sc_analysis_dump分析数据，编写一个 perl 脚本来分析sc_analysis_dump的输出<h3 id="BGP数据"><a href="#BGP数据" class="headerlink" title="BGP数据"></a>BGP数据</h3></li></ol></li></ol>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>IP Internet Topology</title>
    <link href="/2023/07/10/20230710-diary/"/>
    <url>/2023/07/10/20230710-diary/</url>
    
    <content type="html"><![CDATA[<h1 id="IP-Internet-Topology"><a href="#IP-Internet-Topology" class="headerlink" title="IP Internet Topology"></a>IP Internet Topology</h1><h2 id="paper-searching"><a href="#paper-searching" class="headerlink" title="paper searching"></a>paper searching</h2><h3 id="In-the-IP-of-the-Beholder-Strategies-for-Active-IPv6-Topology-Discovery（IMC-’18）"><a href="#In-the-IP-of-the-Beholder-Strategies-for-Active-IPv6-Topology-Discovery（IMC-’18）" class="headerlink" title="In the IP of the Beholder: Strategies for Active IPv6 Topology Discovery（IMC ’18）"></a>In the IP of the Beholder: Strategies for Active IPv6 Topology Discovery（IMC ’18）</h3><h4 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h4><ol><li>随机探测技术——分配探测负载、最小化速率限制的影响、提高探测速率</li><li>hitlist和目标生产方法分析并生成新的目标列表（广度：覆盖整个子网；深度：找到潜在子网）</li><li>阅读目标：<ol><li>探测技术发现</li><li>hitlist和目标产生方法发现</li><li>全文创新灵感和分析方法梳理</li><li>文章探测器试用和拓扑概览</li></ol></li></ol><h4 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h4><ol><li>IPv6应用广泛性举例以及IPv6网络拓扑重要性</li><li>挑战：<ol><li>不可行的大地址空间不能被彻底扫描或均匀有效地采样</li><li>路由器中强制性的ICMPv6速率限制</li><li>未知的地址分配策略和子网结构</li><li>前两个问题的关联性：试图通过探测更多的IPv6地址空间来增加覆盖需要更快的探测速率。然而，增加探测速率是弄巧成拙的，因为这样做会触发更多的速率限制，并且因此会导致更少的发现的路由器接口和更少的代表性拓扑。</li></ol></li><li>目标发现1：虽然几十年的研究已经开发和完善了主动IPv4拓扑发现（例如，[6，20，35，38，56]，这些技术没有解决IPv6特有的上述挑战。<ol><li>[6] Robert Beverly, Arthur Berger, and Geoffrey G. Xie. 2010. Primitives for Active Internet Topology Mapping: Toward High-Frequency Characterization. In Proceedings ofthe CM Internet Measurement Conference (IMC).</li><li>[20] Benoit Donnet, Philippe Raoult, Timur Friedman, and Mark Crovella. 2005. Efficient Algorithms for Large-Scale Topology Discovery. ACMSIGMETRICS Performance Evaluation Review 33, 1 (2005).</li><li>[35] k. claffy, Young Hyun, Ken Keys, and Maria Fomenkov. 2009. Internet Mapping: from Art to Science. In IEEE Cybersecurity Applications for Homeland Security.</li><li>[38] Ken Keys. 2010. Internet-Scale IP Alias Resolution Techniques. SIGCOMM Comput. Commun. Rev. 40, 1 (2010).</li><li>[56] Neil Spring, Ratul Mahajan, and David Wetherall. 2002. Measuring ISP topologies with Rocketfuel. ACMSIGCOMM Computer Communication Review 32, 4 (2002).</li><li>到这我对IPv4探测技术的发现目的似乎已经达成，还要继续读吗？读吧，多了解一下。</li></ol></li><li>目标发现2：生产CAIDA和RIPE跟踪路由定期探测每个全局IPv6 BGP前缀的：：1地址[11，52]。<ol><li>[11] CAIDA. 2018. The CAIDA UCSD IPv6 Topology Dataset. <a href="http://www.caida.org/data/active/ipv6_allpref_topology_dataset.xml">http://www.caida.org/data/active/ipv6_allpref_topology_dataset.xml</a>.</li><li>[52] RIPE NCC. 2018. RIPE Atlas. <a href="https://atlas.ripe.net/">https://atlas.ripe.net/</a>.</li><li>由于在大的IPv6地址空间中采样非常稀疏，因此得到的逻辑拓扑的完整性和质量是未知的。</li></ol></li><li>做法：<ol><li>我们收集了目前从各种来源（例如，BGP、DNS、CDN [22、25、49、51、54]）以及生成的种子（例如，6Gen [46]）</li><li>我们采用了三个步骤的过程来合成12.4M的目标地址，专门制作，以促进拓扑发现</li><li>我们从以下三个方面执行总共45.8M个跟踪：两所美国大学和一所欧盟网络</li><li>我们研究了不同的靶选择方法和参数（例如，最大TTL、协议、探测速度等）找到那些引出最多IPv6拓扑信息的节点</li></ol></li><li>贡献：<ol><li>从七个不同的输入种子集评估各种手段来合成目标地址</li><li>量化随机探测以维持高速率，同时避免ICMPv6速率限制。·</li><li>表征目标列表功率以产生拓扑结果。· </li><li>IPv6子网发现作为拓扑推断的案例研究。· </li><li>IPv6路由器接口级拓扑结果，我们的合成目标列表，以及我们的探测器实现[7]。<h4 id="BACKGROUND-AND-RELATEDWORK"><a href="#BACKGROUND-AND-RELATEDWORK" class="headerlink" title="BACKGROUND AND RELATEDWORK"></a>BACKGROUND AND RELATEDWORK</h4></li></ol></li><li>IPv4拓扑探测技术：除了上文的6、20、35、38、56之外还有：<ol><li>Beverly推出了Yarrp，一个随机化的高速IPv4拓扑探测器：[5] Robert Beverly. 2016. Yarrp’ing the Internet: Randomized High-Speed Active Topology Discovery. In Proceedings ofthe ACM Internet Measurement Conference(IMC).</li></ol></li><li>和IPv6拓扑的区别：<ol><li>尽管先前对IPv4拓扑进行了大量工作，但IPv6至少有两个根本区别：更大的地址空间（稀疏地填充）和激进的ICMPv6速率限制[13，36]。我们探索新的技术，以适应这两个属性在这项工作中。</li></ol></li><li>IPv6拓扑探测技术：<ol><li>CAIDA’s Ark：[11] CAIDA. 2018. The CAIDA UCSD IPv6 Topology Dataset. <a href="http://www.caida.org/data/active/ipv6_allpref_topology_dataset.xml">http://www.caida.org/data/active/ipv6_allpref_topology_dataset.xml</a>.</li><li>RIPE Atlas：[52] RIPE NCC. 2018. RIPE Atlas. <a href="https://atlas.ripe.net/">https://atlas.ripe.net/</a>.</li><li>随机化探测：[28] Erik W. Gaston. 2017. High-frequency mapping ofthe IPv6 Internet using Yarrp. Master’s thesis. Naval Postgraduate School. <a href="http://hdl.handle.net/10945/52982">http://hdl.handle.net/10945/52982</a>.</li><li>IPv6别名解析技术（CAIDA的ITDK的一部分）：这部分不算拓扑探测<ol><li>[42] Matthew Luckie, Robert Beverly, William Brinkmeyer, and kc claffy. 2013. Speed-trap: Internet-Scale IPv6 Alias Resolution. In Proceedings ofthe ACM Internet Measurement Conference (IMC).</li><li>[10] CAIDA. 2018. The CAIDA Internet Topology Data Kit. <a href="http://www.caida.org/data/internet-topology-data-kit">http://www.caida.org/data/internet-topology-data-kit</a>.</li></ol></li></ol></li><li>IPv6 hitlist：互联网中活跃IPv6地址的目录，通常称为hitlist</li></ol><h4 id="TARGET-SELECTION"><a href="#TARGET-SELECTION" class="headerlink" title="TARGET SELECTION"></a>TARGET SELECTION</h4><ol><li>Target Generation<ol><li>接口标识符IID：[33] R. Hinden and S. Deering. 2006. IP Version 6 Addressing Architecture. RFC 4291(Draft Standard).</li><li>暂时弃读</li></ol></li></ol><h3 id="Eﬃcient-Algorithms-for-Large-Scale-Topology-Discovery"><a href="#Eﬃcient-Algorithms-for-Large-Scale-Topology-Discovery" class="headerlink" title="Eﬃcient Algorithms for Large-Scale Topology Discovery"></a>Eﬃcient Algorithms for Large-Scale Topology Discovery</h3><h4 id="Redundancy——冗余"><a href="#Redundancy——冗余" class="headerlink" title="Redundancy——冗余"></a>Redundancy——冗余</h4><ol><li>traceroute从源主机进行探测，第一次TTL为1到达中间节点1，第二次TTL为2先到达中间节点1再到达中间节点2，如此随着TTL的增加，每次越靠近源点的中间节点被访问次数就会增加，这就是测量冗余。</li><li>本文为了方便对测量冗余进行研究，首先进行了分类：<ol><li>分为intra-monitor和inter-monitor：前者是一个monitor访问接口的次数，后者是访问接口的monitor的数量。</li><li>注：monitor可以理解为探测源主机（源点），接口就是中间节点比如路由器的接口，而本文中的探测明显是多个monitor同时进行探测</li></ol></li><li>本文实际上就是一个记录已探测节点的探测策略，算法没什么意思</li></ol><h3 id="Internet-Mapping-from-Art-to-Science"><a href="#Internet-Mapping-from-Art-to-Science" class="headerlink" title="Internet Mapping: from Art to Science"></a>Internet Mapping: from Art to Science</h3><h4 id="ARK项目介绍"><a href="#ARK项目介绍" class="headerlink" title="ARK项目介绍"></a>ARK项目介绍</h4><ol><li>4.1节中提到了ARK使用的探测策略：[23] M. Luckie, Y. Hyun, and B. Huffaker. Traceroute Probe Method and Forward IP Path Inference. In IMC’08, Oct 2008.</li></ol><h3 id="Traceroute-Probe-Method-and-Forward-IP-Path-Inference-In-IMC’08"><a href="#Traceroute-Probe-Method-and-Forward-IP-Path-Inference-In-IMC’08" class="headerlink" title="Traceroute Probe Method and Forward IP Path Inference. In IMC’08"></a>Traceroute Probe Method and Forward IP Path Inference. In IMC’08</h3><h3 id="ARK探测策略"><a href="#ARK探测策略" class="headerlink" title="ARK探测策略"></a>ARK探测策略</h3>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>IP Internet Topology</title>
    <link href="/2023/07/10/IP%20Internet%20Topology/"/>
    <url>/2023/07/10/IP%20Internet%20Topology/</url>
    
    <content type="html"><![CDATA[<h1 id="IP-Internet-Topology"><a href="#IP-Internet-Topology" class="headerlink" title="IP Internet Topology"></a>IP Internet Topology</h1><h2 id="paper-searching"><a href="#paper-searching" class="headerlink" title="paper searching"></a>paper searching</h2><h3 id="In-the-IP-of-the-Beholder-Strategies-for-Active-IPv6-Topology-Discovery（IMC-’18）"><a href="#In-the-IP-of-the-Beholder-Strategies-for-Active-IPv6-Topology-Discovery（IMC-’18）" class="headerlink" title="In the IP of the Beholder: Strategies for Active IPv6 Topology Discovery（IMC ’18）"></a>In the IP of the Beholder: Strategies for Active IPv6 Topology Discovery（IMC ’18）</h3><h4 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h4><ol><li>随机探测技术——分配探测负载、最小化速率限制的影响、提高探测速率</li><li>hitlist和目标生产方法分析并生成新的目标列表（广度：覆盖整个子网；深度：找到潜在子网）</li><li>阅读目标：<ol><li>探测技术发现</li><li>hitlist和目标产生方法发现</li><li>全文创新灵感和分析方法梳理</li><li>文章探测器试用和拓扑概览</li></ol></li></ol><h4 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h4><ol><li>IPv6应用广泛性举例以及IPv6网络拓扑重要性</li><li>挑战：<ol><li>不可行的大地址空间不能被彻底扫描或均匀有效地采样</li><li>路由器中强制性的ICMPv6速率限制</li><li>未知的地址分配策略和子网结构</li><li>前两个问题的关联性：试图通过探测更多的IPv6地址空间来增加覆盖需要更快的探测速率。然而，增加探测速率是弄巧成拙的，因为这样做会触发更多的速率限制，并且因此会导致更少的发现的路由器接口和更少的代表性拓扑。</li></ol></li><li>目标发现1：虽然几十年的研究已经开发和完善了主动IPv4拓扑发现（例如，[6，20，35，38，56]，这些技术没有解决IPv6特有的上述挑战。<ol><li>[6A] Robert Beverly, Arthur Berger, and Geoffrey G. Xie. 2010. Primitives for Active Internet Topology Mapping: Toward High-Frequency Characterization. In Proceedings ofthe CM Internet Measurement Conference (IMC).</li><li>[20] Benoit Donnet, Philippe Raoult, Timur Friedman, and Mark Crovella. 2005. Efficient Algorithms for Large-Scale Topology Discovery. ACMSIGMETRICS Performance Evaluation Review 33, 1 (2005).</li><li>[35] k. claffy, Young Hyun, Ken Keys, and Maria Fomenkov. 2009. Internet Mapping: from Art to Science. In IEEE Cybersecurity Applications for Homeland Security.</li><li>[38] Ken Keys. 2010. Internet-Scale IP Alias Resolution Techniques. SIGCOMM Comput. Commun. Rev. 40, 1 (2010).</li><li>[56] Neil Spring, Ratul Mahajan, and David Wetherall. 2002. Measuring ISP topologies with Rocketfuel. ACMSIGCOMM Computer Communication Review 32, 4 (2002).</li><li>到这我对IPv4探测技术的发现目的似乎已经达成，还要继续读吗？读吧，多了解一下。</li></ol></li><li>目标发现2：生产CAIDA和RIPE跟踪路由定期探测每个全局IPv6 BGP前缀的：：1地址[11，52]。<ol><li>[11] CAIDA. 2018. The CAIDA UCSD IPv6 Topology Dataset. <a href="http://www.caida.org/data/active/ipv6_allpref_topology_dataset.xml">http://www.caida.org/data/active/ipv6_allpref_topology_dataset.xml</a>.</li><li>[52] RIPE NCC. 2018. RIPE Atlas. <a href="https://atlas.ripe.net/">https://atlas.ripe.net/</a>.</li><li>由于在大的IPv6地址空间中采样非常稀疏，因此得到的逻辑拓扑的完整性和质量是未知的。</li></ol></li><li>做法：<ol><li>我们收集了目前从各种来源（例如，BGP、DNS、CDN [22、25、49、51、54]）以及生成的种子（例如，6Gen [46]）</li><li>我们采用了三个步骤的过程来合成12.4M的目标地址，专门制作，以促进拓扑发现</li><li>我们从以下三个方面执行总共45.8M个跟踪：两所美国大学和一所欧盟网络</li><li>我们研究了不同的靶选择方法和参数（例如，最大TTL、协议、探测速度等）找到那些引出最多IPv6拓扑信息的节点</li></ol></li><li>贡献：<ol><li>从七个不同的输入种子集评估各种手段来合成目标地址</li><li>量化随机探测以维持高速率，同时避免ICMPv6速率限制。·</li><li>表征目标列表功率以产生拓扑结果。· </li><li>IPv6子网发现作为拓扑推断的案例研究。· </li><li>IPv6路由器接口级拓扑结果，我们的合成目标列表，以及我们的探测器实现[7]。<h4 id="BACKGROUND-AND-RELATEDWORK"><a href="#BACKGROUND-AND-RELATEDWORK" class="headerlink" title="BACKGROUND AND RELATEDWORK"></a>BACKGROUND AND RELATEDWORK</h4></li></ol></li><li>IPv4拓扑探测技术：除了上文的6、20、35、38、56之外还有：<ol><li>Beverly推出了Yarrp，一个随机化的高速IPv4拓扑探测器：[5] Robert Beverly. 2016. Yarrp’ing the Internet: Randomized High-Speed Active Topology Discovery. In Proceedings ofthe ACM Internet Measurement Conference(IMC).</li></ol></li><li>和IPv6拓扑的区别：<ol><li>尽管先前对IPv4拓扑进行了大量工作，但IPv6至少有两个根本区别：更大的地址空间（稀疏地填充）和激进的ICMPv6速率限制[13，36]。我们探索新的技术，以适应这两个属性在这项工作中。</li></ol></li><li>IPv6拓扑探测技术：<ol><li>CAIDA’s Ark：[11] CAIDA. 2018. The CAIDA UCSD IPv6 Topology Dataset. <a href="http://www.caida.org/data/active/ipv6_allpref_topology_dataset.xml">http://www.caida.org/data/active/ipv6_allpref_topology_dataset.xml</a>.</li><li>RIPE Atlas：[52] RIPE NCC. 2018. RIPE Atlas. <a href="https://atlas.ripe.net/">https://atlas.ripe.net/</a>.</li><li>随机化探测：[28] Erik W. Gaston. 2017. High-frequency mapping ofthe IPv6 Internet using Yarrp. Master’s thesis. Naval Postgraduate School. <a href="http://hdl.handle.net/10945/52982">http://hdl.handle.net/10945/52982</a>.</li><li>IPv6别名解析技术（CAIDA的ITDK的一部分）：这部分不算拓扑探测<ol><li>[42] Matthew Luckie, Robert Beverly, William Brinkmeyer, and kc claffy. 2013. Speed-trap: Internet-Scale IPv6 Alias Resolution. In Proceedings ofthe ACM Internet Measurement Conference (IMC).</li><li>[10] CAIDA. 2018. The CAIDA Internet Topology Data Kit. <a href="http://www.caida.org/data/internet-topology-data-kit">http://www.caida.org/data/internet-topology-data-kit</a>.</li></ol></li></ol></li><li>IPv6 hitlist：互联网中活跃IPv6地址的目录，通常称为hitlist</li></ol><h4 id="TARGET-SELECTION"><a href="#TARGET-SELECTION" class="headerlink" title="TARGET SELECTION"></a>TARGET SELECTION</h4><ol><li>Target Generation<ol><li>接口标识符IID：[33] R. Hinden and S. Deering. 2006. IP Version 6 Addressing Architecture. RFC 4291(Draft Standard).</li><li>暂时弃读</li></ol></li></ol><h3 id="Eﬃcient-Algorithms-for-Large-Scale-Topology-Discovery"><a href="#Eﬃcient-Algorithms-for-Large-Scale-Topology-Discovery" class="headerlink" title="Eﬃcient Algorithms for Large-Scale Topology Discovery"></a>Eﬃcient Algorithms for Large-Scale Topology Discovery</h3><h4 id="Redundancy——冗余"><a href="#Redundancy——冗余" class="headerlink" title="Redundancy——冗余"></a>Redundancy——冗余</h4><ol><li>traceroute从源主机进行探测，第一次TTL为1到达中间节点1，第二次TTL为2先到达中间节点1再到达中间节点2，如此随着TTL的增加，每次越靠近源点的中间节点被访问次数就会增加，这就是测量冗余。</li><li>本文为了方便对测量冗余进行研究，首先进行了分类：<ol><li>分为intra-monitor和inter-monitor：前者是一个monitor访问接口的次数，后者是访问接口的monitor的数量。</li><li>注：monitor可以理解为探测源主机（源点），接口就是中间节点比如路由器的接口，而本文中的探测明显是多个monitor同时进行探测</li></ol></li><li></li></ol>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>APNIC-Lab</title>
    <link href="/2023/06/07/APNIC-Lab/"/>
    <url>/2023/06/07/APNIC-Lab/</url>
    
    <content type="html"><![CDATA[<h1 id="APNIC-Lab"><a href="#APNIC-Lab" class="headerlink" title="APNIC Lab"></a>APNIC Lab</h1><h2 id="Definitions——APNIC-127-2-0：https-www-apnic-net-community-policy-resources-a-h-2-1"><a href="#Definitions——APNIC-127-2-0：https-www-apnic-net-community-policy-resources-a-h-2-1" class="headerlink" title="Definitions——APNIC-127 2.0：https://www.apnic.net/community/policy/resources#a_h_2_1"></a>Definitions——APNIC-127 2.0：<a href="https://www.apnic.net/community/policy/resources#a_h_2_1">https://www.apnic.net/community/policy/resources#a_h_2_1</a></h2><ol><li>IR（Internet Registry）：分配ip地址的机构</li><li>NIR：NIR是由RIR认证成立的国家互联网注册机构，其账户为国家级别的LIR用户</li><li>LIR：一般是ISP<h3 id="APNIC与NIR-Member的关系——APNIC-126：https-www-apnic-net-about-apnic-corporate-documents-documents-membership-nir-membership-agreement"><a href="#APNIC与NIR-Member的关系——APNIC-126：https-www-apnic-net-about-apnic-corporate-documents-documents-membership-nir-membership-agreement" class="headerlink" title="APNIC与NIR Member的关系——APNIC-126：https://www.apnic.net/about-apnic/corporate-documents/documents/membership/nir-membership-agreement/"></a>APNIC与NIR Member的关系——APNIC-126：<a href="https://www.apnic.net/about-apnic/corporate-documents/documents/membership/nir-membership-agreement/">https://www.apnic.net/about-apnic/corporate-documents/documents/membership/nir-membership-agreement/</a></h3></li><li>Recitals：APNIC建立了一个特有的类别：国家互联网注册机构NIR</li><li>Definitions：<ol><li>APNIC指APNIC Pty Ltd ACN 081 528 010，一家依据澳大利亚法律成立的非营利性公司</li></ol></li></ol>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>RIPE Lab</title>
    <link href="/2023/06/06/RIPE-Lab/"/>
    <url>/2023/06/06/RIPE-Lab/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>RIPE NCC IPv4 Transfer Data Abalysis</title>
    <link href="/2023/05/30/RIPE-NCC-IPv4-Transfer-Statistics-Analysis/"/>
    <url>/2023/05/30/RIPE-NCC-IPv4-Transfer-Statistics-Analysis/</url>
    
    <content type="html"><![CDATA[<h1 id="RIPE-NCC-IPv4-Transfer-Data-Abalysis"><a href="#RIPE-NCC-IPv4-Transfer-Data-Abalysis" class="headerlink" title="RIPE NCC IPv4 Transfer Data Abalysis"></a>RIPE NCC IPv4 Transfer Data Abalysis</h1><h2 id="交易频数统计"><a href="#交易频数统计" class="headerlink" title="交易频数统计"></a>交易频数统计</h2><h3 id="以三个月为单位进行统计"><a href="#以三个月为单位进行统计" class="headerlink" title="以三个月为单位进行统计"></a>以三个月为单位进行统计</h3><img src="/2023/05/30/RIPE-NCC-IPv4-Transfer-Statistics-Analysis/image1.png" class=""><p>总体趋势上升，看不出来啥</p><h3 id="以两个月为单位进行统计，从2016到2023年"><a href="#以两个月为单位进行统计，从2016到2023年" class="headerlink" title="以两个月为单位进行统计，从2016到2023年"></a>以两个月为单位进行统计，从2016到2023年</h3><img src="/2023/05/30/RIPE-NCC-IPv4-Transfer-Statistics-Analysis/image2.png" class=""><p>每两个月统计一次，每年的11月和12月都是极大值且为同年的最大值</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>RIPE NCC IPv4 Transfer Statistics Instuction</title>
    <link href="/2023/05/22/RIPE-NCC-IPv4-Transfer-Statistics-Instuction/"/>
    <url>/2023/05/22/RIPE-NCC-IPv4-Transfer-Statistics-Instuction/</url>
    
    <content type="html"><![CDATA[<h1 id="RIPE-NCC-IPv4-Transfer-Statistics-Instuction"><a href="#RIPE-NCC-IPv4-Transfer-Statistics-Instuction" class="headerlink" title="RIPE NCC IPv4 Transfer Statistics Instuction"></a>RIPE NCC IPv4 Transfer Statistics Instuction</h1><p>Site： <a href="https://www.ripe.net/manage-ips-and-asns/resource-transfers-and-mergers/transfer-statistics/within-ripe-ncc-service-region/ipv4-transfer-statistics">https://www.ripe.net/manage-ips-and-asns/resource-transfers-and-mergers/transfer-statistics/within-ripe-ncc-service-region/ipv4-transfer-statistics</a></p><h2 id="RIPE-Resource-Transfer-Policies"><a href="#RIPE-Resource-Transfer-Policies" class="headerlink" title="RIPE Resource Transfer Policies"></a>RIPE Resource Transfer Policies</h2><ol><li>From: <a href="https://www.ripe.net/publications/docs/ripe-682">https://www.ripe.net/publications/docs/ripe-682</a></li><li>该文档第4.0节介绍了转让数据包含了哪些信息：<ol><li>资源提供方的名称</li><li>资源提供方所持有的原数据</li><li>资源接收方的名称</li><li>接收到的每个细分前缀(从原始块派生的每个部分块)或资源</li><li>每个资源被转让的日期</li><li>这是一个遵循RIPE NCC政策的转让还是一个由于组织或企业结构变化（如合并或者收购）导致的转让——在数据中用Transfer Type属性表示，分别为POLICY和MERGER_OR_ACQUISITION<h2 id="IPv4-Address-Allocation-and-Assignment-Policies-for-the-RIPE-NCC-Service-Region"><a href="#IPv4-Address-Allocation-and-Assignment-Policies-for-the-RIPE-NCC-Service-Region" class="headerlink" title="IPv4 Address Allocation and Assignment Policies for the RIPE NCC Service Region"></a>IPv4 Address Allocation and Assignment Policies for the RIPE NCC Service Region</h2></li></ol></li><li>From：<a href="https://www.ripe.net/publications/docs/ripe-733">https://www.ripe.net/publications/docs/ripe-733</a></li><li>第2.0节介绍了IPv4地址的三种主要类型：<ol><li>公共IP地址，全球唯一标识。该文档介绍的两种IPv4地址类型是Provider Aggregatable（PA）和Provider Independent（PI）</li><li>私有IP地址</li><li>特殊用途IP地址</li></ol></li><li>已分配地址空间的状态：<ol><li>LIR会将已分配的地址空间标记为8种状态：（以多大块为单位？）<ol><li>ALLOCATED PA：此地址是已分配给一个LIR的，LIR可以对此地址进行分配或者子分配，但是这种分配和子分配是不可移植的，即当该地址空间转移给其他提供者时，这种分配和子分配就失效了。</li><li>ALLOCATED UNSPECIFIED：此地址是分配给一个RIR用于更进一步分配的。</li><li>SUB-ALLOCATED PA：这个地址空间已经被LIR分配给一个下游网络运营商，并且此运营商可以从中进行分配。所有的该种分配都是PA的，它们不可移植。</li><li>LIR-PARTITIONED PA：LIR账户组织内部记录地址空间分配情况的一种状态。凡是被标记为这种状态的地址都被认为是没有使用的。</li><li>LEGACY：这表明Internet号码资源是在通过区域Internet注册管理机构(通过分配或分配)的当前分层分配系统之前或之外获得的。</li><li>ASSIGNED PA：这个地址空间已经被分配给“issuing LIR infrastructure”或者一个“End User” for use with services provided by the issuing LIR（这段话中的两个名词要理解才能翻译）。当LIR提供的服务结束后该分配不会被保留。<br>注：Network Infrastructure：如果一个IP地址仅用于ISP和End User的联络，那么这个IP地址就算是ISP基础设施（Infrastructure）的一部分。因此上面说的issuing LIR infrastructure应该指该地址用于LIR和End User的联络而不做其他用途。</li><li>ASSIGNED PI：该地址空间已经分配给一个“End User”用于一个特定目的。它不能被进一步分配。<br>注：End User Network：当一个End User有一个使用公共地址空间（即非网络内部私有地址，也非保留地址）的网络时，这个地址空间必须单独使用End User的联系方式注册。如果End User是个人而不是一个组织，那么注册时可以用ISP的联系方式代替。<br>这个End User Network能不能举个例子？<br><a href="https://www.zhihu.com/question/20282767">https://www.zhihu.com/question/20282767</a> 看看这个。。</li><li>ASSIGNED ANYCAST：ASSIGNED ANYCAST:此地址空间已被分配用于TLD任播网络。当不再用于TLD任意播服务时，它不能被保留。</li></ol></li><li>PA和PI地址空间：<ol><li>From：<a href="https://baike.baidu.com/item/%E6%8F%90%E4%BE%9B%E5%95%86%E5%8F%AF%E8%81%9A%E5%90%88%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4/15704289">https://baike.baidu.com/item/%E6%8F%90%E4%BE%9B%E5%95%86%E5%8F%AF%E8%81%9A%E5%90%88%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4/15704289</a></li><li>PA地址空间（provider-aggregatable address space）：提供商可聚合地址空间，指的是一段由RIR分配给互联网服务提供商的IP地址空间。这些IP地址可以被聚合为单一路由条目，以提高互联网上的路有效率。<br>注：使用这种地址的用户在更换上游服务提供商的时候，无法继续使用原先的IP地址，因为这些地址是被分配给服务商的。（根据这段话就可以理解3.1.1的话了）</li><li>PI地址空间（provider-independent address space）：提供商无关地址空间，是由区域互联网注册管理机构（RIR）直接分配给最终用户的一段IP地址。获取了此种地址的用户必须另外联系互联网服务提供商（ISP）来获取互联网的接入服务，并将相关的地址段在互联网上路由。<br>注：通过使用该种地址空间，最终用户可以在不重新为自己的网络编址的情况下，更换所使用的ISP。除此之外，用户还可以使用多条ISP的线路来为自己提供互联网接入，以保证一条线路故障时，不至于与互联网失去连接。<br>但是这种地址空间可能会增加互联网上路由器的负担，因为这种地址不一定能有效地在无类别域间路由系统中进行聚合。</li><li>注：互联网服务提供商ISP，即指提供互联网存取服务的公司。</li></ol></li><li>ALLOCATED PA：</li><li>ASSIGNED PI：</li><li>注：LIR（LIR与RIPE NCC的区别——这个问题涉及ALLOCATED PA和ALLOCATED UNSPECIFIED两种状态的区别），为了说明这个问题，请看如下定义：<ol><li>From：<a href="https://www.ripe.net/about-us/legal/ripe-ncc-lir-account-agreement">https://www.ripe.net/about-us/legal/ripe-ncc-lir-account-agreement</a></li><li>该文档内的Article 1-Definitions：<ol><li>Member：与RIPE NCC签订了RIPE NCC标准服务协议的自然人或法人实体。</li><li>RIPE NCC：一个根据荷兰法律成立的会员制协会，注册办事处设在荷兰阿姆斯特丹。</li><li>RIPE NCC service：通过当前版本的RIPE NCC活动计划中规定的LIR帐户提供的会员服务。</li><li>RIPE Policies：RIPE社区通过开放、自下而上的讨论和基于共识的决策过程采用的政策，该社区是一个向所有对互联网运营感兴趣的各方开放的合作论坛。</li><li>Internet Number Resources：任何互联网标识符，如IP地址(IPv4, IPv6)和自治系统号码。</li><li>LIR Account：本地互联网注册(LIR)帐户，通过该帐户，RIPE NCC向会员提供服务。</li></ol></li></ol></li><li>为何数据列表中没有其他状态地址块的转让信息？<ol><li>哪些资源可以被转移？<ol><li>From：<a href="https://www.ripe.net/manage-ips-and-asns/resource-transfers-and-mergers/inter-rir-transfers">https://www.ripe.net/manage-ips-and-asns/resource-transfers-and-mergers/inter-rir-transfers</a></li><li>AFRINIC目前没有RIR间转移的政策，因此任何类型的资源都不能从这个地区转移或者转移出此地区。</li><li>当资源从其他RIR转移到RIPE NCC时，可以被注册成三种状态：<ol><li>ALLOCATED PA</li><li>ASSIGNED PI</li><li>LEGACY：当提供该地址的RIR通知RIPE NCC该资源是LEGACY状态时，其可以继续保留该状态。如果接受组织与RIPE NCC有合作或者赞助LIR，那么该组织还可以将此资源的状态转换成另一种状态。</li></ol></li></ol></li><li>根据前面的信息以及我的理解，List of Allocated PA Transfers应该是LIR之间的地址交易而List of Assigned PI Transfers是End User之间的交易。因为Allocated PA是指RIR分配给LIR的地址空间，而Assigned PI是RIR分配给End User的。</li><li>验证看看第一个list中的卖家和买家是不是都是LIR：发现一个组织的属性是Other，因此查看了organization对象的org-type属性如下：<ol><li>From：<a href="https://apps.db.ripe.net/docs/04.RPSL-Object-Types/03-Descriptions-of-Secondary-Objects.html#description-of-the-organisation-object">https://apps.db.ripe.net/docs/04.RPSL-Object-Types/03-Descriptions-of-Secondary-Objects.html#description-of-the-organisation-object</a></li><li>“org-type: “ -该属性指定组织的类型。它接受下列固定值之一。用户只能创建类型为“OTHER”的组织对象。其余的值只能由RIPE NCC设置。</li><li>‘IANA’ – Only used for Internet Assigned Numbers Authority</li><li>‘RIR’ – Only used for the five Regional Internet Registries</li><li>‘NIR’ – This is for National Internet Registries (there are no NIRs in the RIPE NCC service region, but it is used by APNIC)</li><li>‘LIR’ – This represents all the Local Internet Registries (the RIPE NCC members)</li><li>‘WHITEPAGES’ – A little-used historical idea for people who have a ‘significant’ presence in the industry but who don’t manage any resources in the RIPE Database.</li><li>‘DIRECT_ASSIGNMENT’ – Used for organisations who have a direct contract with RIPE NCC</li><li>‘OTHER’ – This represents all organisations that do not fit any of the above categories.</li></ol></li><li>上一节中的验证中出现了矛盾：在List of Allocated PA Transfers列表中出现了一条从C.R.T. Informatique S.a.r.l.到Linkt SAS的转让记录，本来此列表中的IP地址应该是LIR之间的转让，可是这两个组织的org-type都是OTHER。<ol><li>与其他来源和去处都是LIR的记录的另一个区别是该交易记录的类型是“MERGER_OR_ACQUISITION”，这说明该组织可能进行了结构重组。</li><li>另一个线索就是：这两个组织在WHOIS数据库中的organization对象的修改时间都是交易结束之后，因此是否可以推测在交易进行时，这两个组织还都是LIR。</li><li>有上一条引出一个问题：我希望通过查询交易记录中涉及组织的org-type来验证此列表是否是LIR之间的交易这个想法是无法实现的，因为有可能有一些组织在交易结束之后修改了org-type，导致无法仅通过数据库当前时间点的视图来验证我的猜想。<h2 id="数据内容分析"><a href="#数据内容分析" class="headerlink" title="数据内容分析"></a>数据内容分析</h2></li></ol></li></ol></li></ol></li><li>分类：<ol><li>From：On IPv4 transfer markets: Analyzing reported transfers and inferring transfers in the wild</li><li>文章中说删除了ARIN报告的26笔交易，这些交易涉及ARIN为互联网交换点（IXP）保留的区块，以及APNIC中涉及同一组织内转移的111笔交易。<ol><li>统计一下该数据中有多少由于组织内部结构变化而导致的转移：</li><li></li></ol></li><li>列表中的转移是否既有RIR之间的转移又有RIR内部的转移？<ol><li>From：<a href="https://www.ripe.net/manage-ips-and-asns/resource-transfers-and-mergers/transfer-statistics">https://www.ripe.net/manage-ips-and-asns/resource-transfers-and-mergers/transfer-statistics</a></li><li>根据该网页可知，本文分析的数据都是RIPE NCC服务区域以内的转让信息，而Inter-RIR的转让信息在<a href="https://www.ripe.net/manage-ips-and-asns/resource-transfers-and-mergers/transfer-statistics/inter-rir/inter-rir-ipv4-transfer-statistics">https://www.ripe.net/manage-ips-and-asns/resource-transfers-and-mergers/transfer-statistics/inter-rir/inter-rir-ipv4-transfer-statistics</a></li></ol></li></ol></li></ol>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Python Crawling Price Data from IPv4.global</title>
    <link href="/2023/05/10/Python-Crawling-Price-Data-from-IPv4-global/"/>
    <url>/2023/05/10/Python-Crawling-Price-Data-from-IPv4-global/</url>
    
    <content type="html"><![CDATA[<h1 id="Python-Crawling-Price-Data-from-IPv4-global"><a href="#Python-Crawling-Price-Data-from-IPv4-global" class="headerlink" title="Python Crawling Price Data from IPv4.global"></a>Python Crawling Price Data from IPv4.global</h1><h2 id="需求：爬取内容如下图"><a href="#需求：爬取内容如下图" class="headerlink" title="需求：爬取内容如下图"></a>需求：爬取内容如下图</h2><img src="/2023/05/10/Python-Crawling-Price-Data-from-IPv4-global/image1.jpg" class=""><h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><h3 id="利用chrome自带工具分析网络请求："><a href="#利用chrome自带工具分析网络请求：" class="headerlink" title="利用chrome自带工具分析网络请求："></a>利用chrome自带工具分析网络请求：</h3><ol><li>这个数据是分页的，并且获取每页的内容时是局部更新而不是整个页面更新，可见这个价格数据可能是通过Ajax（[ˈeˌdʒæks]）请求获取的；   <img src="/2023/05/10/Python-Crawling-Price-Data-from-IPv4-global/image2.png" class=""></li><li>在这个页面按F12可以调出下图页面，按图示操作：   <img src="/2023/05/10/Python-Crawling-Price-Data-from-IPv4-global/image3.jpg" class="">   然后点击页面刷新按钮，则可以在页面里看见请求。然后查看这些请求头、请求参数以及相应内容找到我们要爬取的内容。   <img src="/2023/05/10/Python-Crawling-Price-Data-from-IPv4-global/image4.jpg" class="">   <img src="/2023/05/10/Python-Crawling-Price-Data-from-IPv4-global/image5.png" class="">   <img src="/2023/05/10/Python-Crawling-Price-Data-from-IPv4-global/image6.jpg" class=""></li><li>找到了我们要的数据，接下来就应该写代码爬取了；<h3 id="Python代码"><a href="#Python代码" class="headerlink" title="Python代码"></a>Python代码</h3><h4 id="采用requests模块模拟浏览器发出请求，步骤如下："><a href="#采用requests模块模拟浏览器发出请求，步骤如下：" class="headerlink" title="采用requests模块模拟浏览器发出请求，步骤如下："></a>采用requests模块模拟浏览器发出请求，步骤如下：</h4><ol><li>确定url：通过chrome的网页分析工具确定该请求的url  <img src="/2023/05/10/Python-Crawling-Price-Data-from-IPv4-global/image7.png" class="">  写入代码中：  <img src="/2023/05/10/Python-Crawling-Price-Data-from-IPv4-global/image8.png" class=""></li><li>UA伪装：<ol><li>UA：User Agent（请求载体的身份标识）——https报文中的一个参数；</li><li>Chrome中的UA查看操作：首先打开url进入该网页，然后按F12，点network，勾选Preserve log，然后刷新该网页，选择该url，就可以在request headers中看到User Agent了；  <img src="/2023/05/10/Python-Crawling-Price-Data-from-IPv4-global/image9.png" class=""></li><li>UA检测：门户网站的服务器会检测对应请求的载体身份标识，如果检测到某一请求载体的身份是某一款浏览器，就说明该请求是一个正常请求，但是如果服务器检测到某一请求载体的身份不是浏览器，则为爬虫，定为不正常请求，服务器可能拒绝该次请求——一种反爬机制；</li><li>UA伪装：在request headers中添加user-agent即可，详细代码见request headers一节；</li></ol></li><li>request headers：<br>使用requests发送请求，最好加上request headers，除了进行UA伪装之外，对于这个网页还需要授权信息，就是authorization这个属性。<img src="/2023/05/10/Python-Crawling-Price-Data-from-IPv4-global/image10.png" class="">以防万一还是把request headers全都复制下来。<img src="/2023/05/10/Python-Crawling-Price-Data-from-IPv4-global/image11.png" class="">注：Python字典批量加引号——首先按Ctrl+shift+R，然后按图中输入：<img src="/2023/05/10/Python-Crawling-Price-Data-from-IPv4-global/image12.png" class="">然后就会得到如图所示页面，然后replace即可；<img src="/2023/05/10/Python-Crawling-Price-Data-from-IPv4-global/image13.png" class=""><figure class="highlight dart"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><pre><code class="hljs dart">第一行： (.*?): (.*)<br>第二行： <span class="hljs-string">&#x27;<span class="hljs-subst">$1</span>&#x27;</span>: <span class="hljs-string">&#x27;<span class="hljs-subst">$2</span>&#x27;</span>,       *** 别忘了后面有一个逗号 ***<br></code></pre></td></tr></table></figure></li><li>请求参数：<ol><li>首先要将该请求的参数封装成字典：<img src="/2023/05/10/Python-Crawling-Price-Data-from-IPv4-global/image14.png" class=""><img src="/2023/05/10/Python-Crawling-Price-Data-from-IPv4-global/image20.png" class="">上图中可见对应于Request Payload的POST内容类型为json；<br>封装时要注意数据类型：<img src="/2023/05/10/Python-Crawling-Price-Data-from-IPv4-global/image15.png" class=""></li><li>封装时搞错数据类型会导致服务器返回错误信息：<figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs swift">&#123;<span class="hljs-string">&quot;errors&quot;</span>:[&#123;<span class="hljs-string">&quot;message&quot;</span>:<span class="hljs-string">&quot;Variable <span class="hljs-subst">\&quot;</span>$filter<span class="hljs-subst">\&quot;</span> got invalid value <span class="hljs-subst">\&quot;</span>[]<span class="hljs-subst">\&quot;</span> at <span class="hljs-subst">\&quot;</span>filter.blockSize<span class="hljs-subst">\&quot;</span>; Expected type Int. Int cannot represent non-integer value: <span class="hljs-subst">\&quot;</span>[]<span class="hljs-subst">\&quot;</span>&quot;</span>,<span class="hljs-string">&quot;extensions&quot;</span>:&#123;<span class="hljs-string">&quot;code&quot;</span>:<span class="hljs-string">&quot;BAD_USER_INPUT&quot;</span>&#125;&#125;,&#123;<span class="hljs-string">&quot;message&quot;</span>:<span class="hljs-string">&quot;Variable <span class="hljs-subst">\&quot;</span>$filter<span class="hljs-subst">\&quot;</span> got invalid value <span class="hljs-subst">\&quot;</span>[]<span class="hljs-subst">\&quot;</span> at <span class="hljs-subst">\&quot;</span>filter.registry<span class="hljs-subst">\&quot;</span>; Expected type Rir.&quot;</span>,<span class="hljs-string">&quot;extensions&quot;</span>:&#123;<span class="hljs-string">&quot;code&quot;</span>:<span class="hljs-string">&quot;BAD_USER_INPUT&quot;</span>&#125;&#125;,&#123;<span class="hljs-string">&quot;message&quot;</span>:<span class="hljs-string">&quot;Variable <span class="hljs-subst">\&quot;</span>$filter<span class="hljs-subst">\&quot;</span> got invalid value <span class="hljs-subst">\&quot;</span>3<span class="hljs-subst">\&quot;</span> at <span class="hljs-subst">\&quot;</span>filter.period<span class="hljs-subst">\&quot;</span>; Expected type Int. Int cannot represent non-integer value: <span class="hljs-subst">\&quot;</span>3<span class="hljs-subst">\&quot;</span>&quot;</span>,<span class="hljs-string">&quot;extensions&quot;</span>:&#123;<span class="hljs-string">&quot;code&quot;</span>:<span class="hljs-string">&quot;BAD_USER_INPUT&quot;</span>&#125;&#125;]&#125;<br></code></pre></td></tr></table></figure>其中写到blockSize应该是整型，而我一开始把[]加上了引号，所以才报错；</li><li>上图中的post请求体中的数据是request payload，实际上还有form data，如下图：<img src="/2023/05/10/Python-Crawling-Price-Data-from-IPv4-global/image17.png" class=""><img src="/2023/05/10/Python-Crawling-Price-Data-from-IPv4-global/image19.png" class="">图中可见对应于Form Data的POST内容类型为application&#x2F;x-www-form-urlencoded; charset&#x3D;UTF-8<br>这种类型的数据同样要封装成字典，然后发送请求，如下图：<img src="/2023/05/10/Python-Crawling-Price-Data-from-IPv4-global/image18.png" class=""></li><li>POST提交数据时四种常见的数据类型：<ol><li></li></ol></li></ol></li><li>使用requests获取响应<img src="/2023/05/10/Python-Crawling-Price-Data-from-IPv4-global/image16.png" class=""></li></ol></li></ol>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Nodejs Install Tutorial</title>
    <link href="/2023/05/10/Nodejs-Install-Tutorial/"/>
    <url>/2023/05/10/Nodejs-Install-Tutorial/</url>
    
    <content type="html"><![CDATA[<h1 id="Nodejs-Install-Tutorial"><a href="#Nodejs-Install-Tutorial" class="headerlink" title="Nodejs Install Tutorial"></a>Nodejs Install Tutorial</h1><ol><li><p>PC环境：</p><ol><li>版本    Windows 10 家庭版</li><li>版本号    22H2</li><li>安装日期    ‎2021&#x2F;‎7&#x2F;‎17</li><li>操作系统内部版本    19045.2846</li><li>体验    Windows Feature Experience Pack 120.2212.4190.0</li></ol></li><li><p>nodejs官网：<a href="https://nodejs.org/en">https://nodejs.org/en</a></p><img src="/2023/05/10/Nodejs-Install-Tutorial/image1.png" class=""></li><li><p>详细安装教程（这个教程非常详细）：<a href="https://blog.csdn.net/qq_39038178/article/details/125403896">https://blog.csdn.net/qq_39038178/article/details/125403896</a></p></li><li><p>npm安装报错如下：</p><img src="/2023/05/10/Nodejs-Install-Tutorial/image2.png" class=""><p>解决方案，我用了这个博客的第二种方法，按步骤操作即可：<a href="https://blog.csdn.net/qq_44075310/article/details/128255366">https://blog.csdn.net/qq_44075310/article/details/128255366</a></p></li></ol>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Makefile Tutorial</title>
    <link href="/2022/06/20/Makefile-Tutorial/"/>
    <url>/2022/06/20/Makefile-Tutorial/</url>
    
    <content type="html"><![CDATA[<h3 id="显式规则"><a href="#显式规则" class="headerlink" title="显式规则"></a>显式规则</h3><ol><li>显示规则1：<figure class="highlight makefile"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">目标文件:依赖文件1，依赖文件2……</span><br>     Instructions<br></code></pre></td></tr></table></figure></li><li>举例：利用gcc指令编译hello.c文件<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs stylus">hello<span class="hljs-selector-class">.i</span>:hello<span class="hljs-selector-class">.c</span> #由hello.c生成hello.i，所以hello.i是目标文件，hello.c是依赖文件，这一步是预处理<br>     gcc -E hello<span class="hljs-selector-class">.c</span> -o hello<span class="hljs-selector-class">.i</span><br> hello<span class="hljs-selector-class">.S</span>:hello<span class="hljs-selector-class">.i</span> #编译<br>     gcc -S hello<span class="hljs-selector-class">.i</span> -o hello<span class="hljs-selector-class">.S</span><br> hello<span class="hljs-selector-class">.o</span>:hello<span class="hljs-selector-class">.S</span> #汇编，.o文件即obj文件<br>     gcc -c hello<span class="hljs-selector-class">.S</span> -o hello<span class="hljs-selector-class">.o</span><br> hello:hello<span class="hljs-selector-class">.o</span> #生成可执行文件，Linux中的可执行文件是<span class="hljs-selector-class">.elf</span><br>     gcc hello<span class="hljs-selector-class">.o</span> -o hello<br></code></pre></td></tr></table></figure></li><li>显示规则2：第一个目标文件是最终目标，因此上述四个过程应该反过来写，因为hello这个可执行文件才是最终想要的，这个过程类似于递归执行。<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs stylus">hello:hello<span class="hljs-selector-class">.o</span> #生成可执行文件，Linux中的可执行文件是<span class="hljs-selector-class">.elf</span><br>    gcc hello<span class="hljs-selector-class">.o</span> -o hello<br>hello<span class="hljs-selector-class">.o</span>:hello<span class="hljs-selector-class">.S</span> #汇编，.o文件即obj文件<br>    gcc -c hello<span class="hljs-selector-class">.S</span> -o hello<span class="hljs-selector-class">.o</span><br>hello<span class="hljs-selector-class">.S</span>:hello<span class="hljs-selector-class">.i</span> #编译<br>    gcc -S hello<span class="hljs-selector-class">.i</span> -o hello<span class="hljs-selector-class">.S</span><br>hello<span class="hljs-selector-class">.i</span>:hello<span class="hljs-selector-class">.c</span> #由hello.c生成hello.i，所以hello.i是目标文件，hello.c是依赖文件，这一步是预处理<br>    gcc -E hello<span class="hljs-selector-class">.c</span> -o hello.i<br></code></pre></td></tr></table></figure></li><li>显示规则3：接下来我想删除hello.i，hello.S，hello.o三个中间文件，如果在命令行可以用<code>rm -f hello.o hello.S, hello.i</code>指令来实现，但是如果想写进Makefile文件，这个指令没有目标文件，成为伪目标，写成<code>.PHONY</code>:<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-selector-class">.PHONY</span>:<br><span class="hljs-attribute">clear</span>:<br>     rm -f hello<span class="hljs-selector-class">.o</span> hello<span class="hljs-selector-class">.S</span>, hello.i<br></code></pre></td></tr></table></figure>然后在命令行里输入<code>make clear</code>即可；<h3 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h3></li><li>&#x3D;表示替换，+&#x3D;为追加，:&#x3D;为恒等于；</li><li>可以让我们用到的字符串被替换成变量，比如上面的目标文件hello可以表示成变量；这里变量起到了宏定义的作用；</li><li>用$(变量名)可以使用变量；<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs stylus">TAR=hello<br>CC:=gcc<br><br>$(TAR):hello<span class="hljs-selector-class">.o</span> #生成可执行文件，Linux中的可执行文件是<span class="hljs-selector-class">.elf</span><br>    $(CC) hello<span class="hljs-selector-class">.o</span> -o $(TAR)<br>hello<span class="hljs-selector-class">.o</span>:hello<span class="hljs-selector-class">.S</span> #汇编，.o文件即obj文件<br>    $(CC) -c hello<span class="hljs-selector-class">.S</span> -o hello<span class="hljs-selector-class">.o</span><br>hello<span class="hljs-selector-class">.S</span>:hello<span class="hljs-selector-class">.i</span> #编译<br>    $(CC) -S hello<span class="hljs-selector-class">.i</span> -o hello<span class="hljs-selector-class">.S</span><br>hello<span class="hljs-selector-class">.i</span>:hello<span class="hljs-selector-class">.c</span> #由hello.c生成hello.i，所以hello.i是目标文件，hello.c是依赖文件，这一步是预处理<br>    $(CC) -E hello<span class="hljs-selector-class">.c</span> -o hello.i<br></code></pre></td></tr></table></figure><h3 id="隐含规则"><a href="#隐含规则" class="headerlink" title="隐含规则"></a>隐含规则</h3></li><li>%.c %.o任意的.c或者.o文件； *.c *.o所有的.c或者.o文件，为了方便说明我们换一个例子；<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs stylus">TAR=test<br>OBJ=circle<span class="hljs-selector-class">.o</span> cube<span class="hljs-selector-class">.o</span> <span class="hljs-selector-tag">main</span><span class="hljs-selector-class">.o</span><br>CC:=gcc<br><br>$(TAR):$(OBJ)<br>    $(CC) $(OBJ) -o $(TAR)<br>circle<span class="hljs-selector-class">.o</span>:circle<span class="hljs-selector-class">.c</span><br>    $(CC) -c circle<span class="hljs-selector-class">.c</span> -o circle<span class="hljs-selector-class">.o</span><br>cube<span class="hljs-selector-class">.o</span>:cube<span class="hljs-selector-class">.c</span><br>    $(CC) -c cube<span class="hljs-selector-class">.c</span> -o cube<span class="hljs-selector-class">.o</span><br><span class="hljs-selector-tag">main</span><span class="hljs-selector-class">.o</span>:<span class="hljs-selector-tag">main</span><span class="hljs-selector-class">.c</span><br>    $(CC) -c <span class="hljs-selector-tag">main</span><span class="hljs-selector-class">.c</span> -o <span class="hljs-selector-tag">main</span><span class="hljs-selector-class">.o</span><br><br><span class="hljs-selector-class">.PHONY</span>:<br>clearall:<br>    rm -rf $(OBJ) $(TAR)<br><span class="hljs-attribute">clear</span>:<br>    rm -rf $(OBJ)<br></code></pre></td></tr></table></figure>用上面的通配符写这几行由.c生成.o的代码：<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs makefile">TAR=test<br>OBJ=circle.o cube.o main.o<br>CC:=gcc<br><br><span class="hljs-variable">$(TAR)</span>:<span class="hljs-variable">$(OBJ)</span><br>    <span class="hljs-variable">$(CC)</span> <span class="hljs-variable">$(OBJ)</span> -o <span class="hljs-variable">$(TAR)</span><br>   <br><span class="hljs-section">%.o:%.c</span><br>    <span class="hljs-variable">$(CC)</span> -c %.c -o %.o<br><br><span class="hljs-meta"><span class="hljs-keyword">.PHONY</span>:</span><br><span class="hljs-section">clearall:</span><br>    rm -rf <span class="hljs-variable">$(OBJ)</span> <span class="hljs-variable">$(TAR)</span><br><span class="hljs-section">clear:</span><br>    rm -rf <span class="hljs-variable">$(OBJ)</span><br></code></pre></td></tr></table></figure><h3 id="通配符"><a href="#通配符" class="headerlink" title="通配符"></a>通配符</h3></li><li>$^ 所有的依赖文件</li><li>$@ 所有的目标文件</li><li>$&lt; 所有依赖文件的第一个文件</li><li>等等<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs makefile">TAR=test<br>OBJ=circle.o cube.o main.o<br>CC:=gcc<br>RMRF:=rm -rf<br><br><span class="hljs-variable">$(TAR)</span>:<span class="hljs-variable">$(OBJ)</span><br>    <span class="hljs-variable">$(CC)</span> <span class="hljs-variable">$^</span> -o <span class="hljs-variable">$@</span>  <span class="hljs-comment"># $(TAR)就是所有的目标文件</span><br>   <br><span class="hljs-section">%.o:%.c</span><br>    <span class="hljs-variable">$(CC)</span> -c %.c -o %.o <br><br><span class="hljs-meta"><span class="hljs-keyword">.PHONY</span>:</span><br><span class="hljs-section">clearall:</span><br>    <span class="hljs-variable">$(RMRF)</span> <span class="hljs-variable">$(OBJ)</span> <span class="hljs-variable">$(TAR)</span><br><span class="hljs-section">clear:</span><br>    <span class="hljs-variable">$(RMRF)</span> <span class="hljs-variable">$(OBJ)</span><br></code></pre></td></tr></table></figure><h3 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h3></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>Technology</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Tutorial of Blogging</title>
    <link href="/2022/06/09/Tutorial-of-Blogging/"/>
    <url>/2022/06/09/Tutorial-of-Blogging/</url>
    
    <content type="html"><![CDATA[<ol><li><code>git clone -b hexog https://github.com/unrestrainedpointer/unrestrainedpointer.github.io.git</code></li><li>PC端cmd命令行进入unrestrainedpointer.github.io文件夹</li><li><code>npm install hexo</code></li><li><code>npm install</code></li><li><code>npm install hexo-deployer-git</code></li><li>可以开始写博客了；</li></ol><p>以后每次写博客都执行如下操作：</p><ol><li><code>git pull </code></li><li><code>hexo n  &#39;新文章&#39;</code></li><li>打开source文件夹下的posts文件夹，里面有生成的md文件，编辑文件就可以写博客了；</li><li><code>hexo clean</code></li><li><code>hexo g</code></li><li><code>git add .</code></li><li><code>git commit -m &#39;备注&#39;</code></li><li><code>git push</code></li><li><code>hexo d</code></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>Tutorial of tools</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>OS Lab1</title>
    <link href="/2022/06/09/OS-Lab1/"/>
    <url>/2022/06/09/OS-Lab1/</url>
    
    <content type="html"><![CDATA[<h3 id="通过make生成执行文件的过程"><a href="#通过make生成执行文件的过程" class="headerlink" title="通过make生成执行文件的过程"></a>通过make生成执行文件的过程</h3><ol><li><p>原理和知识点</p></li><li><p>ucore.img是如何一步一步生成的？</p><ol><li><p>在lab1目录下执行make，会在bin中生成一个ucore.img，这是一个包含了BootLoader或OS的硬盘镜像。</p></li><li><p>Makefile说明：</p> <img src="/2022/06/09/OS-Lab1/image1.jpg" class=""><ol><li>这里了:&#x3D;是&#x3D;的变异，所谓的变量又称为宏，是指可以替换为一段字符串的量，如这里的PROJ就可以替换为’challenge’，而:&#x3D;称为简单扩展型变量的赋值，即PROJ的赋值中如果有其他变量直接展开而不是在执行替换时才展开；</li><li>$(variable)是对变量variable的引用；</li></ol>  <img src="/2022/06/09/OS-Lab1/image2.jpg" class=""><ol><li>ifndef variable-name：如果变量‘variable-name’是空值，‘text-if-true’有效，否则，‘text-if-false’有效；</li><li>函数shell：它是make与外部环境的通讯工具。</li><li>函数if：函数if对在函数上下文中扩展条件提供了支持；一个函数if的调用，可以包含两个或三个参数：$(if condition,then-part[,else-part])<ol><li>第一个参数‘condition’，首先把前导、结尾空格去掉，然后扩展。如果扩展为非空字符串，则条件‘condition’为‘真’；如果扩展为空字符串，则条件‘condition’为‘假’。如果条件‘condition’为‘真’,那么计算第二个参数‘then-part’的值，并将该值作为整个函数if的值。</li><li>如果条件‘condition’为‘假’,第三个参数如果存在，则计算第三个参数‘else-part’的值，并将该值作为整个函数if的值；</li><li>如果第三个参数不存在，函数if将什么也不计算，返回空值。</li><li>注意仅能计算‘then-part’和‘else-part’二者之一，不能同时计算。这样有可能产生副作用（例如函数shell的调用）。</li></ol></li><li>echo命令可以用来来显示makefile文件执行的进程：</li><li>grep：正则规则，用于查找；</li><li>\：您可以把一长行在中间插入‘\’使其分为两行，也就是说，一行的尾部是’\’的话，表示下一行是本行的继续行。</li></ol></li><li><p>ucore.img生成说明：</p>  <img src="/2022/06/09/OS-Lab1/image3.jpg" class=""><ol><li>函数call语法：$(call variable,param,param,…)，当make扩展该函数时，它将每一个参数’param’赋值给临时变量$(1)、$(2)等，变量$(0)的值是变量’variable’；如果变量名是内建函数名，则该内建函数将被调用（即使使用该名称的make变量已经存在）。例如，该例子时使用宏reverse函数将参数的顺序翻转：<code>reverse = $(2) $(1)\</code> <code>foo = $(call reverse,a,b)</code>这里变量foo的值是‘b a’。</li><li></li></ol></li><li><p>地方</p></li></ol></li><li><p>一个被系统认为是符合规范的硬盘主引导扇区的特征是什么？</p><h3 id="使用qemu执行并调试lab1中的软件"><a href="#使用qemu执行并调试lab1中的软件" class="headerlink" title="使用qemu执行并调试lab1中的软件"></a>使用qemu执行并调试lab1中的软件</h3></li><li><p>从CPU加电之后执行的第一条指令开始，单步跟踪BIOS的执行：</p></li><li><p>在初始化位置0x7c00设置实地址断点，测试断点正常：</p></li><li></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>Computer Science</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Interview-JVM</title>
    <link href="/2022/05/15/Interview-JVM/"/>
    <url>/2022/05/15/Interview-JVM/</url>
    
    <content type="html"><![CDATA[<h3 id="一、JVM内存五部分组成"><a href="#一、JVM内存五部分组成" class="headerlink" title="一、JVM内存五部分组成"></a>一、JVM内存五部分组成</h3><ol><li>组成：程序计数器（线程私有）+虚拟机栈（线程私有）+本地方法区（线程私有）+堆（线程共享）+方法区&#x2F;永久代（线程共享；</li><li>程序计数器：唯一一个不会出现OOM的区域；</li><li>虚拟机栈：描述Java方法执行的内存模型，每个方法在执行的同时会创建一个栈帧，用于存储局部变量表、操作数栈、动态链接、方法出口等信息；每一个方法从调用到执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程；<ol><li>局部变量表：用于存储局部变量和方法参数；</li><li>操作数栈：Java是采用基于栈的指令集而非基于寄存器的指令集；<ol><li>基于栈的指令集：计算1+1的代码为：  <figure class="highlight gcode"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><pre><code class="hljs gcode">ico<span class="hljs-symbol">nst_1</span><br>ico<span class="hljs-symbol">nst_1</span><br>iadd <br>istore_<span class="hljs-number">0</span> <br></code></pre></td></tr></table></figure></li><li>基于寄存器的指令集：  <figure class="highlight x86asm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs x86asm">move <span class="hljs-built_in">eax</span>,  <span class="hljs-number">1</span><br><span class="hljs-keyword">add</span> <span class="hljs-built_in">eax</span>, <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure></li><li>为什么要用基于栈的指令集：<ol><li>可移植：寄存器由硬件直接提供，程序直接依赖这些硬件寄存器则不可避免要受硬件约束；</li><li>代码相对紧凑；</li><li>编译器实现更加简单，不需要考虑空间分配问题，所需空间都在栈上操作；</li></ol></li><li>栈指令集的缺点：<ol><li>栈架构指令集的主要缺点是执行速度相对来说会稍慢一些。所有主流物理机的指令集都是寄存器架构也从侧面印证了这一点。</li><li>虽然栈架构指令集的代码非常紧凑，但是完成相同功能所需的指令数量一般会比寄存器架构多，因为出栈、入栈操作本身就产生了相当多的指令数量。</li><li>更重要的是，栈实现在内存之中，频繁的栈访问也就意味着频繁的内存访问，相对于处理器来说，内存始终是执行速度的瓶颈。</li><li>尽管虚拟机可以采取栈顶缓存的手段，把最常用的操作映射到寄存器中避免直接内存访问，但这也只能是优化措施而不是解决本质问题的方法。由于指令数量和内存访问的原因，所以导致了栈架构指令集的执行速度会相对较慢。</li></ol></li></ol></li><li>动态链接：在一个class文件中，一个方法要调用其他方法，需要将这些方法的符号引用转化为其在内存地址中的直接引用，而符号引用存在于方法区中的运行时常量池。Java虚拟机栈中，每个栈帧都包含一个指向运行时常量池中该栈所属方法的符号引用，持有这个引用的目的是为了支持方法调用过程中的动态连接(Dynamic Linking)。这些符号引用一部分会在类加载阶段或者第一次使用时就直接转化为直接引用，这类转化称为静态解析。另一部分将在每次运行期间转化为直接引用，这类转化称为动态连接。</li><li>方法出口：当一个方法开始执行时，可能有两种方式退出该方法：<ol><li>正常完成出口、异常完成出口；</li><li>正常完成出口是指方法正常完成并退出，没有抛出任何异常(包括Java虚拟机异常以及执行时通过throw语句显示抛出的异常)。如果当前方法正常完成，则根据当前方法返回的字节码指令，这时有可能会有返回值传递给方法调用者(调用它的方法)，或者无返回值。具体是否有返回值以及返回值的数据类型将根据该方法返回的字节码指令确定。异常完成出口是指方法执行过程中遇到异常，并且这个异常在方法体内部没有得到处理，导致方法退出。</li><li>无论方法采用何种方式退出，在方法退出后都需要返回到方法被调用的位置，程序才能继续执行，方法返回时可能需要在当前栈帧中保存一些信息，用来帮他恢复它的上层方法执行状态。</li></ol></li></ol></li><li>本地方法区：native</li><li>堆：对象和数组都保存在堆中；</li><li>方法区：用于存储JVM加载的类信息、常量、静态变量、即使编译器编译后的代码等数据；<h3 id="二、JVM运行时内存"><a href="#二、JVM运行时内存" class="headerlink" title="二、JVM运行时内存"></a>二、JVM运行时内存</h3></li><li>新生代：Eden+ServivorFrom+ServivorTo：MinorGC——复制算法</li><li>老年代：MajorGC——标记清除算法；</li><li>永久代：存放Class和Meta，GC不会在主程序运行期对永久区域进行处理，所以这也导致了永久代的区域会随着加载Class的增多而胀满，最终抛出OOM异常；Java8中被元空间取代，不再使用虚拟机空间而是采用系统空间；<h3 id="三、垃圾回收GC"><a href="#三、垃圾回收GC" class="headerlink" title="三、垃圾回收GC"></a>三、垃圾回收GC</h3></li><li>怎样判定对象死亡或者不可达？<ol><li>引用计数法：为对象添加一个引用计数器，每当有一个地方引用它时，计数器就加一，引用失效时计数器就减一；</li><li>可达性分析算法：通过一系列的GC Roots对象为起始点开始向下搜索，搜索走过的路径是引用链，当一个对象到GC Roots没有任何引用链相连，那么此对象就是不可达的；<ol><li>哪些对象是GC Roots对象呢？<ol><li>System Class——系统类</li><li>JNI Local——Local variable in native code, such as user defined JNI code or JVM internal code.</li><li>JNI Global ———-Global variable in native code, such as user defined JNI code or JVM internal code.</li><li>Thread Block ———-Object referred to from a currently active thread block. （一个对象存活在一个阻塞的线程中）</li><li>Thread ———-A started, but not stopped, thread.（一个正在运行的线程）</li><li>Busy Monitor ———-Everything that has called wait() or notify() or that is synchronized. For example, by calling synchronized(Object) or by entering a synchronized method. Static method means class, non-static method means object.（用于同步的监控对象）</li><li>Java Local ———-Local variable. For example, input parameters or locally created objects of methods that are still in the stack of a thread.（java 本地变量，输入参数，在线程方法本地创建的对象）</li><li>Native Stack ———-In or out parameters in native code, such as user defined JNI code or JVM internal code. This is often the case as many methods have native parts and the objects handled as method parameters become GC roots. For example, parameters used for file&#x2F;network I&#x2F;O methods or reflection.（ 方法区中的类静态属性引用的对象 ，方法区中的常量引用的对象 ）</li><li>System Class（系统类），Thread Block（一个对象存活在一个阻塞的线程中） ，Thread（线程），Busy Monitor （例如 synchronized(Object)），Java Local （本地变量），Finalizable （存在finalizer 对象的列表中），这几个我们较为常见。</li></ol></li><li>java中的主流虚拟机HotSpot采用可达性分析算法来判断一个对象是否需要进行回收。那么，它是如何实现可达性算法的呢？<ol><li>根节点枚举：先找出可固定作为 GC Roots 的节点，然后沿着引用链去寻找那些无用的垃圾对象。迄今为止，所有收集器在根节点枚举这一步骤时都是必须暂停用户线程，也即 Stop The World，因为如果在分析过程中出现根节点集合中对象的引用关系仍在不断变化的情况，分析结果的准确性也就无法保证了。在对栈内存进行分析时，虚拟机会看哪些位置存储了 Reference 类型，如果发现某个位置确实存的是 Reference 类型，就意味着它所引用的对象这一次不能被回收。但问题是，栈帧的本地变量表里面只有一部分数据是 Reference 类型的，那些非 Reference 类型（基本数据类型）的数据对我们毫无用处，但我们还是不得不对整个栈全部扫描一遍，这是对时间和资源的一种浪费。在 HotSpot 的解决方案中采用了一组称为 OopMap 的数据结构来实现直接找到对象引用，一旦类加载动作完成，HotSpot 就会把栈中代表引用的位置全部记录下来，这样收集器在扫描时就可以直接得知这些消息了。</li><li>安全点：这部分过后去补<h3 id="四、JAVA中四种引用"><a href="#四、JAVA中四种引用" class="headerlink" title="四、JAVA中四种引用"></a>四、JAVA中四种引用</h3><h3 id="五、GC分代回收算法VS分区回收算法"><a href="#五、GC分代回收算法VS分区回收算法" class="headerlink" title="五、GC分代回收算法VS分区回收算法"></a>五、GC分代回收算法VS分区回收算法</h3><h3 id="六、GC垃圾回收器"><a href="#六、GC垃圾回收器" class="headerlink" title="六、GC垃圾回收器"></a>六、GC垃圾回收器</h3></li></ol></li></ol></li></ol></li><li>Serial垃圾回收器——单线程、复制算法，STW；</li><li>ParNew垃圾回收器——Serial+多线程；</li><li>CMS垃圾回收器：Concurrent Mark Sweep——并行标记扫描，是一款并发的老年代垃圾收集器，是通过以最短停顿时间STW为目标的回收器，采用标记清除算法，主要分为以下四个步骤：<ol><li>初始标记：有STW，然后通过可达性分析算法，记录GC ROOTs能直接引用的对象；</li><li>并发标记：从初始标记中GC ROOTs直接关联的对象出发，遍历整个老年代，这个过程耗时较长，但因为是并发流程，无STW；</li><li>重新标记：修正并发标记过程中在初始标记阶段后发生状态改变的对象，使用三色标记中的增量更新算法，此阶段会STW；</li><li>并发清理：同时开启工作线程与GC线程，GC线程主要对未标记的区域进行清理；</li><li>并发重置：重置这次GC过程中的标记数据；</li><li>问题：CPU资源抢占——浮动垃圾——空间碎片——concurrent mode failure问题：并发标记或者并发清理阶段如果又出发了垃圾回收，但是本次垃圾回收又没有进行完，那么则会出发concurrent mode failure，这时会进入单线程收集，先STW，然后使用serial old垃圾回收器来回收；</li></ol></li><li>G1垃圾回收器：Garbage First</li><li>对象的内存结构：<ol><li>对象的内存构成——一个实例对象是以怎样的形态存在内存中的？Java对象保存在堆中的时候，由以下三部分组成：<br>1. 对象头：由两个字组成<ol><li>Mark Word：用于存储对象自身的运行时数据，如hashcode、GC分代年龄、锁状态标志、线程持有锁、偏向线程ID、偏向时间戳等；</li><li>klass pointer：对象指向它的类元数据的指针，JVM通过这个指针来确定这个对象是哪个类的实例；<br>2. 实例数据：对象的属性字段、父类信息；<br>3. 对齐填充： 默认情况下，Java虚拟机堆中对象的起始地址需要对齐至8的倍数。如果一个对象用不到8N个字节则需要对其填充，以此来补齐对象头和实例数据占用内存之后剩余的空间大小。</li></ol></li><li>为什么要对齐数据？<ol><li>字段内存对齐的其中一个原因，是让字段只出现在同一CPU的缓存行中。如果字段不是对齐的，那么就有可能出现跨缓存行的字段。也就是说，该字段的读取可能需要替换两个缓存行，而该字段的存储也会同时污染两个缓存行。这两种情况对程序的执行效率而言都是不利的。其实对其填充的最终目的是为了计算机高效寻址。</li><li>如果对象在cache中跨数据行存储，则无法添加缓存锁，和volatile的实现机制矛盾；</li></ol></li></ol></li><li>常量池：分为class文件常量池、运行时常量池、全局字符串常量池以及基本类型包装类对象常量池；<ol><li>class文件常量池：class文件常量池主要存放两大常量：字面量和符号引用；<ol><li>字面量：文本字符串、用final修饰的成员变量；</li><li>符号引用：类和接口的全限定名、字段的名称和描述符、方法的名称和描述符；</li></ol></li><li>运行时常量池：方法区的一部分</li></ol></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>Computer Science</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Interview-ComputerNet</title>
    <link href="/2022/05/11/Interview-ComputerNet/"/>
    <url>/2022/05/11/Interview-ComputerNet/</url>
    
    <content type="html"><![CDATA[<ol><li>应用层<ol><li>HTTP状态码：<ol><li>定义：HTTP 状态码由三个十进制数字组成，第一个十进制数字定义了状态码的类型。响应分为五类：信息响应(100–199)，成功响应(200–299)，重定向(300–399)，客户端错误(400–499)和服务器错误 (500–599)；</li><li>1**为信息相应，服务器收到请求，需要请求者继续执行操作；</li><li>2**为成功响应，信息被服务器正确接收并执行；</li><li>3**为重定向，需要客户端进一步执行操作；</li><li>4**为客户端错误，请求包含语法错误或无法完成请求；</li><li>5**为服务器错误，服务器在处理请求过程中发生了错误；</li><li>206：Partial Content——部分内容。服务器成功处理了部分GET请求；</li></ol></li><li>HTTP与HTTPS的区别：</li><li>非对称加密和对称加密的数学基础：</li><li>HTTP报文格式：<ol><li>客户端请求</li><li>消息：客户端发送一个HTTP请求到服务器的请求消息包括以下格式：请求行（request line）、请求头部（header）、空行和请求数据四个部分组成，其中请求行包括请求方法、URL和协议版本；</li><li>HTTP响应也由四个部分组成，分别是：状态行、消息报头、空行和响应正文。</li></ol></li><li>HTTP收发消息的具体流程：</li><li>Cookie和Session以及Token：</li><li>Session的设计：</li><li>HTTP请求方法：</li><li></li></ol></li><li>传输层<ol><li>TCP三次握手与四次挥手：</li><li>TCP的closewait和timewait：</li><li>TCP拥塞控制机制：</li><li>TCP可靠传输机制：</li><li></li></ol></li><li>网络层</li><li>链路层</li><li>物理层</li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>Computer Science, Interview</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Interview Sort Algorithm</title>
    <link href="/2022/04/28/Interview-Sort-Algorithm/"/>
    <url>/2022/04/28/Interview-Sort-Algorithm/</url>
    
    <content type="html"><![CDATA[<ol><li>冒泡排序：每趟扫描都会使最大元素归位；<ol><li>不变性和单调性：经过k趟扫描之后，最大的前k个元素必然归位；经过k趟扫描交换之后，待求解问题的有效规模减小到n-k；</li><li>时间复杂度：O($n^2$)，稳定；</li></ol></li><li>插入排序：将无序后缀中的第一个元素插入到有序前缀中；<ol><li>不变性：在任何时刻，相对于当前节点e&#x3D;S[r]，前缀S[0,r)总是业已有序；</li><li>时间复杂度：O($n^2$)；</li></ol></li><li>选择排序：从无序前缀中找到最大的放到有序后缀的最前面；<ol><li>不变性：在任何时刻，后缀S(r,n)已经有序，且不小于前缀S[0,r]；</li><li>时间复杂度：$\theta(n^2)$;</li></ol></li><li>归并排序：划分到最小之后合并；<ol><li>时间复杂度：O(logn)，稳定；</li></ol></li><li>快速排序：S[low, hi)中一个轴点mi，满足S[low, mi)中的元素小于S[mi]，而S(mi, hi)中的元素大于S[mi]，因此当S转化为有序向量S&#96;后，有如下情况：<ul><li>S[mi]&#x3D;S&#96;[mi];</li><li>S[low, mi)和S&#96;[low, mi)中的元素相同；</li><li>S(mi, hi)和S&#96;(mi, hi)中的元素相同；</li></ul><ol><li>轴点构造算法partition()——快速划分算法：O(logn)；</li><li>快排平均时间复杂度：O(nlogn)；</li></ol></li><li>希尔排序：</li><li>堆排序：</li><li>计数排序：</li><li>桶排序：</li><li>基数排序：</li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>Computer Science</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Interview Java</title>
    <link href="/2022/04/28/Interview-Java/"/>
    <url>/2022/04/28/Interview-Java/</url>
    
    <content type="html"><![CDATA[<ol><li><p>ConcurrentHashMap原理：HashMap是线程不安全的，ConcurrentHashMap采用分段锁技术将数据分段存储，每段分配一个锁。</p><ol><li>存储结构：<ol><li>Segments数组：数组的每个元素是一个segment数组——存储元素，segment内部存在竟态条件，同时访问一个segment的时候才会抢占锁；</li><li>一个Segment相当于一个小的hashmap，里边的table数组继承自ReentrantLock；</li><li>JDK1.8之后，取消了segments字段，直接采用transient HashEntry&lt;K,V&gt;[] table保存数据，采用table数组元素作为锁，从而实现对每一行数据加锁，并发控制使用Synchronized和CAS加锁；</li></ol></li><li>初始化：<ol><li>除了第一行的数组，其他数组都在添加第一元素时才被初始化；</li><li>第一次添加元素时初始长度为16；</li><li>当添加位置冲突达到8时，如果数组长度小于64就扩容，否则链表转化为红黑树；</li><li>每个数组的负载因子为0.75；</li><li></li></ol></li></ol></li><li><p>HashTable也是线程安全的，get&#x2F;put等操作是synchronized，实现效率较低；</p></li><li></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>Computer Science</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Interview-Database</title>
    <link href="/2022/04/23/Interview-Database/"/>
    <url>/2022/04/23/Interview-Database/</url>
    
    <content type="html"><![CDATA[<ol><li>数据库三大范式：<ol><li>第一范式：列不可拆分；</li><li>第二范式：非主键依赖主键而非主键的一部分；</li><li>第三范式：非主键只依赖主键而非其他非主键；</li></ol></li><li>MySQL的binlog有几种录入格式？分别有什么区别？<ol><li>statement：只记录SQL语句而不记录每一行的变化，减少了binlog的记录量，节约了IO提高了性能；</li><li>row：记录了每一行的变化，但是文件的保存信息太多，日志量太大；</li><li>mixed：普通操作使用statement记录，无法使用statement的时候使用row；</li></ol></li><li>MyISAM索引和InnoDB索引的区别：</li><li>InnoDB引擎的4大特性：<ol><li>插入缓冲：</li><li>二次写：</li><li>自适应哈希索引：</li><li>预读：</li></ol></li><li>索引的类型：<ol><li>主键索引：数据列不允许重复，不允许为null，一个表只能有一个主键。</li><li>唯一索引：数据列不允许重复，允许为null，一个表允许多个列创建唯一索引。</li><li>普通索引，没有唯一性的限制，允许为null。</li><li>全文索引；</li></ol></li><li>最左前缀匹配原则：mysql可以创建联合索引即多列的索引，一个索引可以包含最多16列。</li><li>聚簇索引：将数据和索引存储到一起；</li><li>非聚簇索引：数据和索引分开存放，索引的叶子节点指向数据的对应行；</li><li>联合索引：</li><li>事务：一个不可分割的数据库操作系列，也是数据库并发控制的基本单位，其执行结果必须使数据库从一种一致性状态转变为另一种一致性状态。</li><li>事务的四大特性ACID：<ol><li>原子性：事务是最小执行单位，不允许分割。事务的原子性是通过undo log日志进行实现的，当事务需要回滚的时候，InnoDB就调用undo log日志进行SQL语句的撤销，实现数据的回滚；</li><li>一致性：多个事务对同一个数据读取的结果是相同的；</li><li>隔离性：并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间的数据库是独立的；</li><li>持久性：事务提交后对数据库的改变是不受故障等因素影响的，事务的持久性是通过InnoDB存储引擎中的redo log日志来实现的；</li></ol></li><li>脏读、幻读、不可重复读：<ol><li>脏读：一个事务更改数据还未提交，另一个事务在此时就读了还未提交的数据，如果另一个事务回滚了或者没有顺利提交，那么这个数据就没有被修改，但这个没有修改的数据却被读了，这显然不合理；</li><li>不可重复读：一个事务在两次查询之中数据不一致；</li><li>幻读：先后两此查询的数据得到的行数不同；</li></ol></li><li>事务隔离级别：为了达到事务的四大特性，数据库定义了4种不同的事务隔离别；<ol><li>Read-uncommitted：允许读取尚未提交的数据变更，可能导致脏读、不可重复读、幻读；</li><li>Read committed：允许读取并发事务已提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。</li><li>Repeatable read：可重复读，对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己修改的，可以阻止脏读和不可重复读，但幻读仍有可能发生。</li><li>Serializable：可串行化，所有事务一次逐个执行，完全符合ACID；</li></ol></li><li>隔离级别与锁的关系：<ol><li>在Read uncommitted级别下，读取数据不需要加共享锁，这样就不会跟被修改的数据上的排他锁冲突；</li><li>Read committed级别下读操作需要加共享锁，但是在语句执行完以后释放共享锁；</li><li>Repeatable Read级别下，读操作需要加共享锁，但是在事务提交之前并不释放共享锁；</li><li>Serializable：该级别锁定整个范围的键，并一直持有锁，直到事务完成；</li></ol></li><li>锁分类：<ol><li>行级锁：只针对当前操作的行进行加锁，行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但开锁的开销也最大，行级锁分为共享锁和排他锁，有死锁；</li><li>表级锁：对当前操作的整张表加锁。实现简单消耗资源少。表级锁分为共享读锁和独占写锁（排他锁），开销小，加锁快，无死锁。</li><li>页级锁：粒度介于行级锁和表级锁中间的一种锁，表级锁加速快，但冲突多，行级锁冲突少，但速度慢。所以取了折中的页级，一次锁定相邻的一组记录；</li></ol></li><li>共享锁和排他锁：<ol><li>共享锁又叫读锁，当用户要进行数据的读取时对数据加上共享锁。</li><li>排他锁又叫写锁：排他锁只可以加一个，它和其他的排他锁、共享锁互斥；</li></ol></li><li>InnoDB存储引擎的锁算法有哪三种？<ol><li>Record lock：单个行记录上的锁；</li><li>Gap Lock：间隙锁，锁定一个范围，不包括记录本身；</li><li>Next-key lock：锁定一个范围包括范围本身；</li></ol></li><li>MySQL的主从复制：<ol><li>将原来的数据库复制一个一样的，原来的叫主数据库，复制的叫从数据库。从数据库会与主数据库进行数据同步，保持二者的数据一致性；</li><li>主从复制的原理是通过binlog日志实现的。binlog日志中保存了数据库中所有SQL语句，通过对binlog日志中SQL的复制，然后再进行语句的执行即可实现同步；</li><li>实现主从复制主要靠三个线程：运行在主服务器的发送线程，用于发送binlog到从服务器，运行在从服务器上的I&#x2F;O线程用于读取从主服务器发来的binlog内容并拷贝到本地的中继日志中，运行在从服务器上的SQL线程用于读取中继日志中关于数据更新的SQL语句并执行，从而实现主从库的数据一致；</li></ol></li><li>MVCC：Multi-Version Concurrency Control，多版本并发控制协议，实现Repeatable Read隔离级别的机制；</li><li>redo log日志是InnoDB引擎层的日志，用来记录事务操作引起数据的变化，记录的是数据页的物理修改：<ol><li>预写式技术：InnoDB引擎对数据的更新，是先将更新数据记录写入redo log日志，然后在系统空闲的时候或者是按照设定的更新策略再将日志中的内容更新到磁盘中。</li><li>redo log的大小是固定的，为了能够持续不断的对更新记录进行写入，在redo log日志中设置了两个标志位，checkpoint和write_pos，分别记录了擦除的位置和写入的位置，[write_pos, checkpoint]之间是可写入的区间；</li><li>当write_pos标志到了日志结尾时，会从结尾跳到日志头部，重新循环写入。</li><li>当write_pos追上checkpoint表示redo log已经写满，需要停下来删除一些记录，执行checkpoint规则腾出可写空间；</li><li>checkpoint规则：checkpoint触发后，将buffer中脏数据页和脏日志页都刷新到磁盘；</li><li>脏数据：内存中未刷到磁盘的数据；</li><li>redo log中最重要的概念就是缓冲池buffer pool，这是在内存中分配的一个区域，包含了磁盘中部分数据页的映射，作为访问数据库的缓冲；</li><li>当请求读取数据时，会先判断是否在缓冲池命中，如果未命中才会在磁盘上进行检索后放入缓冲池；</li><li>当请求写入数据时，会先写入缓冲池，缓冲池中修改的数据会定期刷新到磁盘中。这一过程也称为刷脏；</li><li>因此，当数据修改时，除了修改buffer pool中的数据，还会在redo log中记录这次操作；当事务提交时，会根据redo log的记录对数据进行刷盘。如果MySQL宕机，重启时可以读取redo log中的数据，对数据库进行恢复，从而保证了事务的持久性。</li></ol></li><li>脏日志刷盘：<ol><li>为了保证日志文件的持久化，也需要经历将日志记录从内存写入磁盘的过程。redo log分为两部分，一是存在易失性内存中的缓存日志redo log buff，二是保存在磁盘上的redo log file；</li><li>脏日志刷盘调用操作系统的fsync操作，fsync函数用于同步内存中所有已修改的文件数据到储存设备；</li></ol></li><li>二进制日志binlog：是一种服务层日志，所有引擎都可以使用；<ol><li>还称为归档日志，记录数据库的变化情况。所有涉及数据变动的操作都要记录其中。因此有了binlog可以很方便的对数据进行复制和备份，因而也常用作主从库的同步；</li><li>binlog输入磁盘的几种模式：<ol><li>STATEMENT：基于SQL语句的复制；</li><li>ROW：基于行的复制——被修改的行写入binlog；</li><li>MIXED：基于上述两种的混合复制；</li></ol></li><li>binlog和redo log的区别：<ol><li>redo log是一种物理日志，记录的是实际数据库中数据页上的变化信息，即某个位置变成了什么数据；</li><li>binlog是一种逻辑日志，是记录操作的，比如sql语句，也可以记录某一行数据变0化或者二者结合——一般的复制使用STATEMENT，对于STATEMENT模式无法复制的操作使用ROW模式保存；</li><li>redo log是基于crash recovery，保证MySQL宕机后的数据恢复；而binlog是基于point-in-time recovery，保证服务器可以基于时间点对数据进行恢复，或者对数据进行备份；</li><li>binlog是追加写入，不会覆盖已写文件，redo log日志是循环写入和擦除；</li></ol></li></ol></li><li>回滚日志undo log：引擎层日志；<ol><li>当数据库修改时除了记录redo log还会生成对应的undo log，如果事务执行失败或者调用了rollback，就利用undolog将数据回滚到修改之前的样子；</li><li>undo log不同于redo log，它属于逻辑日志，它对SQL语句执行相关的信息进行记录。当发生回滚时，InnoDB引擎会根据undo log日志中的记录做与之相反的工作。</li><li>undo日志一个是提供回滚操作，二是实现MVCC；</li></ol></li><li>一条SQL语句的执行过程：<ol><li>连接建立；</li><li>SQL查询解析器：类似于编译；</li><li>SQL查询优化器：优化SQL语句，生成执行计划，选择相应索引，选择相应的引擎去执行SQL；</li><li>执行器：调用存储引擎接口执行SQL语句；</li><li>存储引擎读取Buffer Pool缓冲，未命中则去磁盘中查找；</li><li>将这条语句加载到undo log中；</li><li>redo log将数据被修改后的情况记录在redo log buffer中；</li><li>事务被提交时，将redo log buffer中的数据写入redo log file中；</li><li>将本次记录写入binlog文件；</li><li>将binlog文件名字和更新内容在binlog中的位置记录在redo log中，同时在redo log最后添加commit标记；</li></ol></li><li>索引失效：<ol><li>违反最左前缀原则</li><li>在索引列上使用内置函数；</li><li>查询条件包含or</li><li>使用不等于</li><li>like以通配符开头</li><li>字符串不加单引号</li><li>当mysql估计使用全表扫描要比使用索引快，则不使用索引</li></ol></li><li>InnoDB和MyISAM的区别：<ol><li>InnoDB支持事务，MyISAM不支持事务；</li><li>InnoDB支持外键，MyISAM不支持外键；</li><li>InnoDB支持MVCC，MyISAM不支持；</li><li>MyISAM有一个变量保存了整个表的总行数，可以直接读取总行数，而InnoDB需要扫描全表；</li><li>InnoDB支持表、行级锁，MyISAM只支持表级锁；</li><li>InnoDB必须有主键，而MyISAM可以没有主键；</li><li>InnoDB按主键大小有序插入，MyISAM记录是按插入顺序保存；</li></ol></li><li>MySQL的索引：<ol><li>按数据结构维度：<ol><li>B+树索引；</li><li>哈希索引；</li><li>全文索引；</li><li>R-Tree索引；</li></ol></li><li>物理存储维度：<ol><li>聚簇索引；</li><li>非聚簇索引；</li></ol></li><li>逻辑维度：<ol><li>主键索引；</li><li>普通索引；</li><li>联合索引；</li><li>唯一索引；</li><li>空间索引；</li></ol></li></ol></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>Computer Science</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Rudimentary Skills of Computer Science</title>
    <link href="/2022/04/20/Interview-Rudimentary-Skills-of-Computer-Science(1)/"/>
    <url>/2022/04/20/Interview-Rudimentary-Skills-of-Computer-Science(1)/</url>
    
    <content type="html"><![CDATA[<ol><li>GC过程：<ol><li>JVM将堆内存分为两部分：<ol><li>新生代：分为伊甸园—幸存区From—To；</li><li>老年代；</li></ol></li><li>伊甸园满了——Minor GC采用复制算法把存活对象放入To中，幸存对象寿命+1，清空伊甸园，From和To互换；</li><li>伊甸园又满了——把伊甸园和From中的对象都放到To中，再清空伊甸园和From，From和To互换；</li><li>又来个对象，把新生代回收完也放不下了，老年代也放不下，触发Full GC，从新生代到老年代都要回收。</li><li>Minor GC会触发Stop the World，暂停用户线程；</li><li>寿命保存在对象头中，用4bits表示，因此最大寿命是15；</li><li>大对象直接晋升到老年代；</li><li>一个线程内的outOfMemory不一定会使Java线程结束；</li></ol></li><li>创建线程的方式：<ol><li>继承Thread类并重写run方法；</li><li>实现Runnable接口并重写run方法；</li><li>实现Callable接口并实现call()方法，使用FutureTask类来包装Callable对象；</li></ol></li><li>创建线程池的方式：<ol><li>线程池的好处：<ol><li>关键词：减少——时间、系统资源占用——资源不足——大量同类线程——内存——过渡切换。</li><li>线程池的好处在于可以减少创建和销毁线程所需要的时间和系统资源的开销，解决资源不足的问题。如果不使用线程池，有可能造成系统创建大量同类线程而导致消耗完内存或者“过渡切换”的问题。</li></ol></li><li>Executors创建线程池，由于底层的阻塞队列使用的是LinkedBlockQueue实现的，而LinkedBlockQueue的最大长度为Integer.MAX_VALUE，当我们不设置线程池容量时就意味着可以添加如此多的任务而导致OutOfMemory——可以使用ThreadPoolExecutor来指定BlockQueue的容量。</li><li>Executors创建线程的四种方式：<ol><li>newCachedThreadPool：可缓存线程池，线程池无限大。</li><li>newFixedThreadPool：定长线程池，可控制最大并发数，超出的线程会在队列中等待。</li><li>newScheduledThreadPool：定长线程池，支持定时及周期性任务执行。</li><li>newSingleThreadPool：单线程化的线程池，它会用唯一的工作线程来执行任务，保证所有任务按照指定优先级来执行。</li></ol></li></ol></li><li>TCP四次回收中closewait和timewait的作用：<ol><li>closewait是服务器在告诉客户端自己成功接收到释放连接的请求后，由于自己还可能有一些数据没有传送完成而进入的状态。</li><li>timewait是客户端在告诉服务器自己成功接收到服务器释放连接的请求后，考虑到由于客户端确认报文丢失而引起服务器超时重传，如果此时客户端已经关闭，就会用RST包来响应服务器，这会让服务器认为有错误发生。</li><li>timewait的问题：在高并发短连接的情况下，服务器可能会有多个连接处于timewait状态，这有可能会导致连接占用的文件描述符达到上限而无法继续建立正常连接。</li></ol></li><li>cookie和session有哪些区别？<ol><li>cookie是保存在浏览器端的用于保存用户信息的数据，会在浏览器向服务器发送请求时被携带发送在服务器上。通常它用于告知服务端两个请求是否来自同一浏览器，通常有以下三方面用途：<ol><li>回话状态管理：用户登录状态、购物车、游戏分数或者其他需要记录的信息。</li><li>个性化信息：用户自定义设置、主题等等。</li><li>浏览器行为跟踪：跟踪分析用户行为等。</li></ol></li><li>session代表着服务器和客户端一次回话的过程，session对象存储特定用户会话所需要的属性及配置信息。这样，当用户在应用程序的web页之间跳转时，存储在session对象中的变量不会消失。当浏览器关闭会话或者session超时失效时会话结束。</li><li>cookie和session的区别：<ol><li>作用范围不同：cookie保存在客户端，session保存在服务端；</li><li>存取方式不同：cookie只能保存ASCII码，session可以保存任意的数据类型。</li><li>有效期不同：cookie可以设置为长时间保持，比如我们经常使用的默认登录功能，session一般失效时间较短，客户端关闭或者session超时都会失效。</li><li>隐私策略不同：cookie存储在客户端容易遭到不法窃取，session存储在服务端安全性好一些；</li><li>存储大小不同：单个cookie保存的数据不能超过4K，session可以存储的数据远高于cookie；</li></ol></li><li>为什么需要cookie和session，他们有什么关联？<ol><li>浏览器使用的HTTP协议的无状态性导致浏览器不知道正在使用他们的是谁，通过cookie和session的配合可以告诉服务器本次操作的用户是否登录、是哪个用户在操作。</li><li>cookie和session的配合流程：<ol><li>用户第一次请求服务器的时候，服务器根据用户提交的信息，创建对应的session，请求返回时将此session的唯一标识信息SessionID返回给客户端，客户端接收后将此信息存储在cookie中并同时记录此SessionID所属的域名。</li><li>用户第二次访问服务器的时候，请求会自动判断此域名是否存在cookie信息，如果存在会将cookie发送给服务端，服务端从中获取SessionID，据此查找相应的session，如果没有证明用户没登录或登录失败，找到则说明用户已登录并且可移执行后续操作。</li></ol></li></ol></li><li>如果浏览器禁止cookie，那么怎么保障整个机制的正常运转？<ol><li>第一种方案可以在请求后携带SessionID参数；</li><li>第二种方案可以采用Token机制。Token是服务端生成的一个字符串作为客户端请求的标识，第一次用户登录后服务器产生一个Token交给客户端，以后的每次请求都携带这个Token就好而无需再次登录验证。</li></ol></li><li>分布式session问题，多台服务器共同支撑前端用户请求，用户两次访问服务端连接到的是不同的服务器，那么session怎么保证有效？<ol><li>可以将每个请求按照访问IP的hash分类，这样来自同一IP固定访问一个服务器。</li><li>session复制：当一个服务器的session改变之后，该节点会将session序列化广播给所有服务器。</li><li>共享session：服务端无状态化，将用户的session等信息采用缓存中间件统一管理。</li></ol></li></ol></li><li>Java中的锁有哪些？</li><li>ReentrantLock和synchronized有什么区别？</li><li>ConcurrentHashMap是怎么保证线程安全的？</li><li>mysql索引的最左匹配：</li><li>mysql事务：</li><li>mysql什么情况下会加锁？</li><li>select语句没有走索引，有哪些原因？</li><li>动态代理的实现？</li><li>深拷贝与浅拷贝：</li><li>Java中volatile关键字：<ol><li>变量的可见性保证：两个线程分别在不同的核中运行时会把内存中的共享变量读取到各自的cache中，因此某个线程改变变量之后由于cache写策略的不同可能导致另一线程对于本线程的更改不可见，因此会使用volatile关键字保证变量可见性。<ol><li>在读取volatile变量时，线程中所有在volatile之后的变量都会重新从内存中读取到cache，而volatile之前的变量由于没有解释器没有检查到volatile关键字因此还是从cache中读取，可能不是最新值；</li><li>在写入volatile变量时，线程中所有在volatile之前的变量都会从cache写入内存，而volatile之后的变量由于解释器没有检测到这个关键字，因此不会故意触发写直达的策略；</li></ol></li><li>happens-before保证：指令重排的情况下，happens-before原则保证以下两点：<ol><li>排在volatile之前的写指令不能重排序到volatile之后；</li><li>排在volatile之后的读指令不能重排序到volatile之前；</li></ol></li><li>综上所述，volatile关键字提供的是读写原则：<ol><li>从volatile开始的所有读都是从内存读而不是从cache读；</li><li>发现volatile关键字需要写变量时将cache中的内容更新到内存中；</li><li>在这两个原则的基础上可以实现上述两个功能；</li></ol></li><li>cache的读写策略的转换应该是操作系统层面的功能，JVM应该是调用了操作系统的接口来实现一下的功能：<ol><li>不从cache读而从内存读，读完更新cache；</li><li>将cache的内容写入内存；</li></ol></li></ol></li><li>volatile进阶：<ol><li>volatile实现：反汇编可知，volatile的汇编代码中加了lock前缀，查询IA-32手册可知lock前缀的功能：<ol><li>在修改内存操作时，使用LOCK前缀去调用加锁的读-修改-写操作，这种机制用于多处理器系统中处理器之间进行可靠的通讯，具体描述如下：<ol><li>在Pentium和早期的IA-32处理器中，LOCK前缀会使处理器执行当前指令时产生一个LOCK#信号，这种总是引起显式总线锁定出现；</li><li>在Pentium4、Inter Xeon和P6系列处理器中，加锁操作是由高速缓存锁或总线锁来处理。如果内存访问有高速缓存且只影响一个单独的高速缓存行，那么操作中就会调用高速缓存锁，而系统总线和系统内存中的实际区域内不会被锁定。同时，这条总线上的其它Pentium4、Intel Xeon或者P6系列处理器就回写所有已修改的数据并使它们的高速缓存失效，以保证系统内存的一致性。如果内存访问没有高速缓存且&#x2F;或它跨越了高速缓存行的边界，那么这个处理器就会产生LOCK#信号，并在锁定操作期间不会响应总线控制请求</li></ol></li><li>IA-32架构提供了几种机制用来强化或弱化内存排序模型，以处理特殊的编程情形。这些机制包括：<ol><li>I&#x2F;O指令、加锁指令、LOCK前缀以及串行化指令等，强制在处理器上进行较强的排序</li><li>SFENCE指令（在Pentium III中引入）和LFENCE指令、MFENCE指令（在Pentium4和Intel Xeon处理器中引入）提供了某些特殊类型内存操作的排序和串行化功能</li><li>这些机制可以通过下面的方式使用：总线上的内存映射设备和其它I&#x2F;O设备通常对向它们缓冲区写操作的顺序很敏感，I&#x2F;O指令（IN指令和OUT指令）以下面的方式对这种访问执行强写操作的排序。在执行了一条I&#x2F;O指令之前，处理器等待之前的所有指令执行完毕以及所有的缓冲区都被都被写入了内存。只有取指令和页表查询能够越过I&#x2F;O指令，后续指令要等到I&#x2F;O指令执行完毕才开始执行。</li></ol></li><li>缓存锁：缓存锁定是某个CPU对缓存数据进行更改时，会通知缓存了该数据的CPU抛弃缓存的数据或者从内存重新读取。</li><li>两种不能使用缓存锁的情况：<ol><li>第一种情况是操作的数据不能被缓存在处理器内部，或者操作的数据跨多个缓存行（cache line）时，则处理器会调用总线锁定——由此可知为什么对象的内存结构中必须有对齐从而避免加载入缓存时跨多个数据行了，除了有效率的考虑外还有就是加缓存锁的保证；</li><li>第二种情况是处理器不支持缓存锁定，对于Intel 486和Pentium处理器，就算锁定的内存区域在处理器的缓存行中也会调用总线锁定。</li></ol></li></ol></li><li>过程：工作内存Work Memory其实就是对CPU寄存器和高速缓存的抽象，或者说每个线程的工作内存也可以简单理解为CPU寄存器和高速缓存。<ol><li>那么当写两条线程Thread-A与Threab-B同时操作主存中的一个volatile变量i时，Thread-A写了变量i，那么<ol><li>Thread-A发出LOCK#指令</li><li>发出的LOCK#指令锁总线（或锁缓存行），同时让Thread-B高速缓存中的缓存行内容失效</li><li>Thread-A向主存回写最新修改的i</li><li>Thread-B读取变量i，那么：</li></ol></li><li>Thread-B发现对应地址的缓存行被锁了，等待锁的释放，缓存一致性协议会保证它读取到最新的值<ol><li>由此可以看出，volatile关键字的读和普通变量的读取相比基本没差别，差别主要还是在变量的写操作上。</li></ol></li></ol></li></ol></li><li>Java序列化机制：<ol><li>将对象转化为字节流存储在磁盘用于网络运输或者独立于进程保存；</li><li>可以实现Serializable接口，用ObjectOutputStream类的writeObject方法序列化，但是这个类中的成员必须也是可序列化的；</li><li>序列化是不会将同一个对象重复序列化；</li><li>可以使用transient关键字修饰那些可序列化类中不想序列化的对象；</li></ol></li><li>https对称加密和非对称加密的详细过程：<ol><li>对称加密：加密和解密用一把钥匙，对称加密如果秘钥被劫持会导致信息不安全；</li><li>非对称加密：用公钥加密的信息需要私钥解开，用私钥加密的信息需要公钥解开，非对称加密中一方保存私钥，发送公钥，则即使公钥被劫持也只能解密由私钥加密的传输信息而无法解密由公钥加密的传输信息——非对称加密可以保证单个方向传输的安全性；</li><li>由于非对称加密可以保证单方向传输的安全性，可以采用非对称加密从浏览器向服务器传输加密的对称秘钥——服务器将公钥明文传输给浏览器，浏览器生成对称秘钥，用公钥加密后传送给服务器，此时即使被劫持也无法获取到秘钥。然后两方用这个秘钥加密信息进行通信。</li><li>中间人攻击：劫持服务器发送给浏览器的公钥A，替换为公钥B发送给浏览器，浏览器用公钥B加密对称秘钥X之后，中间人就可以用私钥B&#96;解密得到X，再将X用公钥A加密发送给浏览器，如此中间人就获得了对称秘钥X；</li><li>数字证书：网站在使用HTTPS之前需要向CA机构申领一份数字证书，数字证书中含有证书持有者信息。公钥信息等，服务器会把证书传送给浏览器，浏览器从证书中获取公钥。</li><li>如何防止数字证书被篡改？<ol><li>运用数字签名：<ol><li>服务端用数据生成散列值并用自己的私钥加密形成签名附加到数据之后，由于运用的是私钥因此中间人无法改变数据后重新生成签名。</li><li>浏览器用公钥解密签名得到散列值并自己用数据生成散列值查看二者是否相同，一致则数字签名有效。</li></ol></li><li>中间人不可能掉包证书：由(1)知中间无法更改证书内容，因此如果掉包，那么浏览器只需要对比证书上的域名和自己申请访问的域名就知道证书有没有被掉包了。</li></ol></li></ol></li><li>HTTP三次握手就是TCP三次握手；</li><li>输入URL后浏览器响应的过程：<ol><li>输入地址：浏览器在历史记录、书签等地方搜索到已输入字符串可能对应的URL，然后提示补全。Chrome浏览器甚至会从缓存中把网页展示出来，此时我们还没有回车，网页就展示出来了。</li><li>请求发起后，浏览器需要解析域名，如果本地hosts文件没有找到对应的IP地址，浏览器就会发送DNS请求到本地DNS服务器——一般是ISP，比如中国电信、中国移动等；</li><li>本地DNS服务器首先查询缓存，如果有这条记录就直接返回结果，这个过程是递归式查询。如果没有记录就询问DNS根服务器；</li><li>根服务器没有的话就会告诉本地DNS服务器去域服务器上查询，并给出地址，这个过程是迭代的；</li><li>本地DNS向域服务器发出请求，域服务器告诉本地DNS服务器它所请求的域名的解析服务器的地址；</li><li>本地DNS服务器向解析服务器发送请求，获得IP地址，然后将此地址返回给浏览器，并保存在自己的缓存中；</li><li>浏览器会以一个随机端口向服务器的80端口发送TCP连接请求，这个请求到达服务器进入网卡，进入TCP&#x2F;IP协议栈、防火墙最终进入WEB程序，处理请求。</li></ol></li><li>TCP拥塞控制：<ol><li>慢开始——由于一开始不知道网络的负荷情况，为了避免大量的数据字节传送进网络，因此采用从小到大增加拥塞窗口的策略，即从1开始每次乘2；</li><li>拥塞避免——当窗口大小达到阈值之后采用线性增长。当达到拥塞时，此时将新的慢开始的阈值变为此时窗口值的一半，并将窗口重新变为1。</li></ol></li><li>TCP流量控制：</li><li>InnoDB特性，B树和B+树的区别：</li><li>乐观锁和悲观锁：<ol><li>悲观锁：每次更新数据时都会认为别人会抢占数据进行更改；</li><li>乐观锁：访问数据认为不会有人抢占数据，等到更新的时候再判断这个数据是否被更改；</li></ol></li><li>mysql主从复制：</li><li>HTTP中POST和GET的区别：</li><li>自旋锁和互斥锁有什么区别？</li><li>String、StringBuffer和StringBuilder之间的区别？</li><li>TCP&#x2F;IP参考模型：<ol><li>应用层：OSI参考模型中的会话层、表示层、应用层功能合并到应用层实现，协议有FTP、Telnet、DNS、SMTP、HTTP等；</li><li>传输层：TCP、UDP；</li><li>网络互联层：网络层，IP、IGMP、ICMP；</li><li>网络接入层：对应于OSI的物理层和链路层。TCP&#x2F;IP并未真正描述这一层，而是由参与互联的各网络使用自己的物理层和链路层协议，然后与TCP&#x2F;IP的网络接入层连接；</li></ol></li><li>Java中的反射机制：</li><li>进程和线程的区别：<ol><li>进程是操作系统分配资源的最小单位；</li><li>线程是进程的一部分，描述指令流执行状态。它是进程中指令执行流的最小单元，是CPU调度的最小单位；</li><li>线程&#x3D;进程-共享资源（代码段、数据段、打开文件）</li><li>进程拥有一个完整的资源平台而线程只独享指令流执行的必要资源如寄存器和栈；</li><li>线程能够减少并发执行的时间和空间开销<ol><li>线程的创建和销毁比进程需要的时间短；</li><li>同一进程内线程的切换比进程短；</li><li>由于同一进程内各线程间共享内存和文件资源，可以不通过内核进行直接通信；</li></ol></li></ol></li><li>进程通信的方式：<ol><li>直接通信：两个进程之间建立一对一的链路；</li><li>间接通信：通过操作系统维护的消息队列实现进程间的消息接收和发送；<ol><li>每个消息队列都有一个唯一标识；</li><li>只有共享了相同消息队列的进程才能通信；</li></ol></li><li>几种具体的实现方式：<ol><li>信号：进程之间的软中断通知和处理机制；</li><li>管道：进程间基于内存文件的通信机制；</li><li>消息队列；</li><li>共享内存：把同一个物理内存区域同时映射到多个进程的内存地址空间；</li></ol></li></ol></li><li>Telnet协议：</li><li>虚拟内存：</li><li>内核态和用户态解释一下：</li><li>Map的遍历方式：<ol><li>把容量设置为2^n这样可以将取余操作转化为按位与操作提高效率（key%M&#x3D;key&amp;&amp;(M-1)），但是由于这相当于截取key末尾的n个比特（即低位掩码）而导致key的高位比特对于哈希值没有影响，因此很大程度上降低了散列的随机性和均匀性。</li><li>为了改善c中对于随机性和均匀性的降低， Java采用hashcode的高16位和低16位异或，这样使得高位也能影响散列值，能降低hash碰撞；  </li><li>1.8开始扩容之后不用重新hash而是直接定位原节点在新数组的位置，因为数组容量扩大2倍无非就是高位多了一个1，那如果原来数据的hashcode的高位为1则重hash的值比原来大了一个旧数组的容量，为0则没变；</li></ol></li><li>Java线程阻塞的情况：<ol><li>线程休眠：sleep方法放弃CPU使用权，但不放弃锁；</li><li>线程等待获取锁才能进行下一步操作；</li><li>线程执行wait进入阻塞状态；</li><li>等待相关资源；</li><li>请求连接时；</li><li>读取线程等待数据；</li><li>线程写数据时可能会出现；</li></ol></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>Computer Science</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Relation</title>
    <link href="/2022/04/17/Relation/"/>
    <url>/2022/04/17/Relation/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
    <tags>
      
      <tag>Mathematics</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Poetry(1)</title>
    <link href="/2022/04/17/Poetry/"/>
    <url>/2022/04/17/Poetry/</url>
    
    <content type="html"><![CDATA[<div class="code-wrapper"><pre><code class="hljs">                               时时灌溉，常教玉树气回根。                               日日栽培，莫使金花精脱蒂。                                                        保神养气谓之精，情性原来一禀形。                            心乱神昏诸病作，形衰精败道元倾。                            三花不就空劳碌，四大萧条枉费争。                            土木无功金水绝，法身疏懒几时成！                            归根复命是还丹，养到纯阳再换坛。                            不晓个中消息意，圣基虽入道难完。                            阳极阴生姤即连，此中消息要师传。                            含章在内神功妙，知者夺来造化权。                            金液还丹教外传，五行四象火功全。                            求师诀破其中奥，了悟源流好上船。                            人生在世是浮沤，背理违天谁肯休。                            任尔堆金多积玉，怎能买得命长留。                            存诚去妄法虽良，究竟难逃生死乡。                            何若金丹微妙诀，超凡入圣了无常。                            火生于木本藏锋，不会钻研莫强攻。                            祸发总由斯害己，要须制服觅金公。                            真阳不在肾中藏，强闭阴精非妙方。                            会得神观微妙法，消除色欲不张遑。                            心动意迷志不专，修行往往被他牵。                            劝君戒惧勤防备，莫起风尘障道缘。                            大地仙乡列圣曹，蓬莱分合镇波涛。                            瑶台影蘸天心冷，巨阙光浮海面高。                            五色烟霞含玉籁，九霄星月射金鳌。                            西池王母常来此，奉祝三仙几次桃。                            方丈巍峨别是天，太元宫府会神仙。                            紫台光照三清路，花木幽浮五色烟。                            金凤自多槃蕊阙，玉膏谁逼灌芝田。                            碧桃紫李新成熟，又换仙人信万年。                            一日清闲自在仙，六神和合保平安。                            丹田有宝休寻道，对境无心莫问禅。                            弃却瓢囊摵碎琴，如今不恋水中金。                            自从一见黄龙后，始觉从前错用心。</code></pre></div>]]></content>
    
    
    
    <tags>
      
      <tag>Poetry</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Graham-Scan</title>
    <link href="/2022/04/17/Graham-Scan/"/>
    <url>/2022/04/17/Graham-Scan/</url>
    
    <content type="html"><![CDATA[<ol><li><p>前言——两种态度：</p><ol><li>自然态度：接受前提并继续思考；</li><li>哲学态度：反思前提并继续颠覆——怀疑的美妙；</li></ol></li><li><p>Convex hull：</p><ol><li>输入：平面上的n个点的集合Q；</li><li>输出： CH(Q): Q的convex hull；</li><li>Q的convex hull是一个最小凸多边形P，Q的点或者在P上或者在P内；</li><li>凸多边形P是具有如下性质多边形：连接P内任意两点的边都在P内</li></ol></li><li><p>Graham Scan：</p><ol><li>选取一个点作为极点，将所有点按照与极点形成的极角由小到大排序；</li><li>从极点开始选取凸包边界点：<ol><li>用栈保存遍历到当前节点的过程中凸包边界的候选点；</li><li>每次遍历选取栈顶第二个节点作为极点，将栈顶节点与极点形成的极角和遍历节点与极点形成的极角作比较：<ol><li>当前者大于后者时，删除栈顶节点；</li><li>当前者小于后者时，保留栈顶节点；</li><li>当前者等于后者时，如果栈顶节点的极径大于遍历节点的极径则保留栈顶节点，否则删除；</li></ol></li><li>遍历节点入栈，成为新的栈顶；</li><li>直到遍历结束，栈中节点就是凸包边界点的集合；</li></ol></li><li>初始化栈，极点和极角最小的节点；</li></ol></li><li><p>算法过程中点的关系：</p><ol><li>遍历过程中每一个点都进入了栈成为了凸包边界候选点；</li><li>每次循环过程中只做了一件事：借助栈顶第二个节点和遍历到的当前节点决定栈顶节点的去留；</li><li>遍历的顺序是节点与极点形成的极角的递增顺序；</li><li>算法的不变性是每次循环开始时栈中节点形成了遍历序列中当前遍历节点之前的点集的凸包；</li></ol></li><li><p>考察算法的思考过程：</p><ol><li>首先确定遍历顺序，将人为解决问题方法中的遍历顺序用极角表达；</li><li>确定循环中每个点去留所取决的因素；</li><li>本算法中遍历到的节点不是作为待操作节点而存在，而是作为待操作节点选择操作的判断条件而存在，这是因为凸包边界节点的选取进度和遍历进度不一致却又相关而导致的——即我们当前需要考虑是否在凸包中的节点可能是P2而遍历到的节点可能是P5；</li><li>当我们用数学概念（极坐标系）配合数学操作（计算、比较大小）表达人为解决问题的方法时，出现了如下情况可以采用的方法：<ol><li>结果集递增的速度和问题集遍历的速度不一致，可以采用判断（if语句）使两者匹配，此时循环中操作的量即是遍历到的量；</li><li>随着问题集的遍历（问题规模的递增），结果集中的某些元素会出现不确定性，本算法中是最新加入结果集中的元素的保留与否随着问题集的递增具有不确定性，此时循环中操作的变量是结果集中具有不确定性的元素；</li><li>以上两种情况的不同点在于结果集和问题集规模变化过程的关系：同步递增、异步递增、规模变化非单调（Graham Scan算法中随着问题集规模的递增会出现结果集规模递减的现象，而这种递减在每次循环中最多是1）；</li><li>(c)中的着眼点在于问题解决过程中问题集和结果集规模变化的关系；</li></ol></li></ol></li><li><p>结论：根据（5）中结论，我们在程序设计过程中为了确定程序在问题集递增过程中的具体操作可以着眼于问题集递增对于结果集的每次递增的影响；</p></li><li><p>考察算法思考过程中运用了理性的哪些内涵：</p><ol><li>我们为什么要如上方式地确定遍历顺序？<ol><li>一种回答是因为这能解决问题，但我们在确定这种顺序时并不确定问题可以因此得到解决。我们没有理由的选择“按照某种顺序一个个考察问题集中的节点”，比如本算法的按照二维空间边界的顺序（数学上表达为极角），再比如按照大小顺序、排列顺序，即便是我们所谓的不按顺序也可以理解为“按随机顺序”，总之我们必须一个一个地考察问题集中的节点，这是最根本的前提，也就是我们的理性总是解析式的考察问题，这是由于理性具有分辨性质的缘故，因此确定问题集规模递增的顺序是第一步；</li><li>何为顺序？顺序的产生是基于量的性质和时空性质，比如我们常见的大小顺序就是基于量，先后顺序是基于时空，而在数学的帮助下，空间可以被我们量化表达，即空间观念和量的观念可以被思维的同一性关联起来（或者说空间观念和量观念的构成中具备了相同的理性因素）</li><li>空间观念中的基本观念：<ol><li>位置观念：<ol><li>点的位置可以借助各种坐标系表达；</li><li>线的位置可以借助方程表达；</li><li>形的位置可以借助什么表达呢？</li></ol></li></ol></li></ol></li></ol></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>Computer Science, Philosophy</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Stream in Java</title>
    <link href="/2022/04/12/Stream-in-Java/"/>
    <url>/2022/04/12/Stream-in-Java/</url>
    
    <content type="html"><![CDATA[<ol><li>流是什么：<ol><li>流是支持数据处理操作的源生成的元素序列，源可以是数组、文件、集合、函数。流不是数据结构并不保存数据，它的主要目的在于计算。</li></ol></li><li>流的生成：<ol><li>通过集合生成：<code>Stream&lt;Integer&gt; steam=new ArrayList&lt;Integer&gt;().stream();</code> </li><li>通过数组生成：<code>IntStream stream=Arrays.stream(new int[]&#123;1,2,3&#125;);</code></li><li>通过值生成：<code>Stream&lt;Integer&gt; stream=Stream.of(1,2,3,4,5,6);</code></li><li>通过文件生成：<code>Stream&lt;Integer&gt; stream=Files.lines(Paths.get(&quot;data.txt&quot;), Charset.defaultCharset());</code></li><li>通过函数生成：<code>Stream&lt;Integer&gt; stream=Stream.iterate(0, n-&gt;n+2).limit(5);</code>iterate()方法 接受两个参数，第一个是初始化值，第二个为进行的函数操作，因为iterate生成的是无限流，通过limit方法对流进行了截断；</li><li>generator：<code>Stream&lt;Double&gt; stream=Stream.generate(Math::random).limit(5);</code></li></ol></li><li>流的操作类型：<ol><li><p>中间操作：</p><ol><li>filter：条件筛选  <figure class="highlight apache"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">List</span>&lt;Integer&gt; list=Arrays.asList(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>);<br><span class="hljs-attribute">Stream</span>&lt;Integer&gt; stream=list.stream().filter(i-&gt;i&gt;<span class="hljs-number">3</span>);<br><span class="hljs-attribute">result</span>:<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span><br></code></pre></td></tr></table></figure></li><li>distinct：去除重复元素；</li><li>limit：返回指定流的个数；</li><li>skip：跳过流中的元素；</li><li>map：流映射——将接受的元素映射为另一个元素  <figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs mathematica"><span class="hljs-built_in">List</span><span class="hljs-operator">&lt;</span><span class="hljs-built_in">String</span><span class="hljs-operator">&gt;</span> <span class="hljs-variable">list</span><span class="hljs-operator">=</span><span class="hljs-built_in">Arrays</span><span class="hljs-operator">.</span><span class="hljs-variable">asList</span><span class="hljs-punctuation">(</span><span class="hljs-string">&quot;Java 8&quot;</span><span class="hljs-operator">,</span><span class="hljs-string">&quot;Lambdas&quot;</span><span class="hljs-operator">,</span><span class="hljs-string">&quot;In&quot;</span><span class="hljs-operator">,</span><span class="hljs-string">&quot;Action&quot;</span><span class="hljs-punctuation">)</span><span class="hljs-operator">;</span><br><span class="hljs-built_in">List</span><span class="hljs-operator">&lt;</span><span class="hljs-built_in">Integer</span><span class="hljs-operator">&gt;</span> <span class="hljs-variable">length</span><span class="hljs-operator">=</span><span class="hljs-variable">list</span><span class="hljs-operator">.</span><span class="hljs-variable">stream</span><span class="hljs-punctuation">(</span><span class="hljs-punctuation">)</span><span class="hljs-operator">.</span><span class="hljs-variable">map</span><span class="hljs-punctuation">(</span><span class="hljs-built_in">String</span><span class="hljs-string">::length</span><span class="hljs-punctuation">)</span><span class="hljs-operator">.</span><span class="hljs-variable">collect</span><span class="hljs-punctuation">(</span><span class="hljs-variable">Collectors</span><span class="hljs-operator">.</span><span class="hljs-variable">toList</span><span class="hljs-punctuation">(</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">)</span><span class="hljs-operator">;</span><br><span class="hljs-variable">result</span><span class="hljs-operator">:</span><span class="hljs-punctuation">[</span><span class="hljs-number">6</span><span class="hljs-operator">,</span><span class="hljs-number">7</span><span class="hljs-operator">,</span><span class="hljs-number">2</span><span class="hljs-operator">,</span><span class="hljs-number">6</span><span class="hljs-punctuation">]</span><br></code></pre></td></tr></table></figure></li><li>flatMap：流转换——将一个流中的每个值都转换为另一个流；</li><li>allMatch：匹配所有元素  <figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">List&lt;Integer&gt; <span class="hljs-built_in">list</span>=<span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">Arrays</span>.</span></span><span class="hljs-keyword">as</span><span class="hljs-constructor">List(1,2,3,4,5)</span>;<br><span class="hljs-built_in">list</span>.stram<span class="hljs-literal">()</span>.all<span class="hljs-constructor">Match(<span class="hljs-params">i</span>-&gt;<span class="hljs-params">i</span>&gt;3)</span>;<br>result:<span class="hljs-literal">false</span><br></code></pre></td></tr></table></figure></li><li>anyMatch：匹配一个元素</li><li>noneMatch：全部不匹配</li></ol></li><li><p>终端操作：</p><ol><li>count：计算流中元素个数；</li><li>findFirst：查找第一个；</li><li>findAny：随机查找一个；</li><li>reduce：将流中的元素组合<ol><li>用于求和<code>int sum=list.stream().reduce(0, Integer::sum);</code></li></ol></li><li>min&#x2F;max：获取最大最小值；</li><li>sum：求和；</li><li>averagingXXX：求平均值；</li><li>forEach：遍历</li><li>joining拼接流中的元素 <figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs lasso"><span class="hljs-built_in">String</span> result=<span class="hljs-built_in">list</span>.stream().<span class="hljs-built_in">map</span>(<span class="hljs-built_in">String</span><span class="hljs-type">::toLowerCase</span>).collect(Collectors.joining(<span class="hljs-string">&quot;-&quot;</span>));<br></code></pre></td></tr></table></figure></li></ol></li></ol></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>Conputer Science, Java</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Recursion and iteration</title>
    <link href="/2022/04/10/Recursion-and-iteration/"/>
    <url>/2022/04/10/Recursion-and-iteration/</url>
    
    <content type="html"><![CDATA[<figure class="highlight markdown"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></div></td><td class="code"><pre><code class="hljs markdown"><span class="hljs-bullet">156.</span> 给你一个二叉树的根节点 root ，请你将此二叉树上下翻转，并返回新的根节点。<br><br>你可以按下面的步骤翻转一棵二叉树：<br><br><span class="hljs-code">    原来的左子节点变成新的根节点</span><br><span class="hljs-code">    原来的根节点变成新的右子节点</span><br><span class="hljs-code">    原来的右子节点变成新的左子节点</span><br><span class="hljs-code"></span><br>上面的步骤逐层进行。题目数据保证每个右节点都有一个同级节点（即共享同一父节点的左节点）且不存在子节点。<br><br></code></pre></td></tr></table></figure><figure class="highlight fsharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs fsharp"><span class="hljs-keyword">class</span> Solution &#123;<br>    <span class="hljs-keyword">public</span> TreeNode upsideDownBinaryTree(TreeNode root) &#123;<br>        <span class="hljs-keyword">if</span>(root<span class="hljs-operator">==</span><span class="hljs-literal">null</span>)<br>            <span class="hljs-keyword">return</span> root;<br>        TreeNode res<span class="hljs-operator">=</span><span class="hljs-keyword">new</span> TreeNode(root.<span class="hljs-keyword">val</span>);<br>        <span class="hljs-keyword">while</span>(root.left<span class="hljs-operator">!=</span><span class="hljs-literal">null</span>)&#123;<br>            res<span class="hljs-operator">=</span>root.right<span class="hljs-operator">!=</span><span class="hljs-literal">null</span><span class="hljs-operator">?</span><span class="hljs-keyword">new</span> TreeNode(root.left.<span class="hljs-keyword">val</span>, <span class="hljs-keyword">new</span> TreeNode<br>                (root.right.<span class="hljs-keyword">val</span>), res)<span class="hljs-operator">:</span><span class="hljs-keyword">new</span> TreeNode(root.left.<span class="hljs-keyword">val</span>, <span class="hljs-literal">null</span>,<br>                res);<br>            root<span class="hljs-operator">=</span>root.left;<br>        &#125;<br>        <span class="hljs-keyword">return</span> res;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>受本题启发在这里总结关于迭代和递归过程中问题规模递减的顺序和迭代&#x2F;递归过程顺序的关系。</p><ol><li>对于本而言考虑这组输入：<code>root = [1,2,3,4,5]</code>；</li><li>本题问题规模递减的顺序是：<ol><li>生成子树<code>[2,3,1]</code>；</li><li>生成子树<code>[4,5,2,null,null,3,1]</code>；</li></ol></li><li>由(2)可知，问题解决的顺序与遍历的顺序是相同的，都是从前往后&#x3D;&gt;迭代解决；</li></ol><p>在来考虑递归的解决顺序：</p><ol><li><p>自顶向下的递归：当前问题在被遍历到的时候就已经计算进答案中；</p><ol><li>问题的解决顺序与遍历的顺序是相同的；</li></ol></li><li><p>自底向上的递归：当前问题在子问题解决的基础上解决，因此递归到更小的子问题然后根据更小子问题的返回值解决当前问题；</p><ol><li>解决问题的顺序和遍历的顺序相反；</li></ol></li><li><p>(1)和(2)两种递归的区别：</p><ol><li>有返回值的情况：<ul><li>自顶向下return recursion(n-1)——问题规模递减到最小时可以得到最终的答案，返回上一层时不需要做进一步处理;</li><li>自底向上return f(recursion(n-1));——问题规模减小到最小时可以得到规模最小的子问题答案，返回上一层需要处理后才能得到高层次的答案；</li></ul></li><li>没有返回值的情况：<ul><li>自顶向下recursion(n-1);</li><li>自底向上由于需要子问题的结果作为当前问题的结果因此必须有返回值；</li><li>但是有一个特例，当传入引用类型的数据作为参数时，答案可以记录在这个引用变量里；</li></ul></li></ol></li><li><p>分析二叉树深度优先搜索的递归过程：</p> <figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-built_in">public</span> <span class="hljs-type">void</span> recursion(<span class="hljs-type">int</span>[] nums, <span class="hljs-type">int</span> depth, <span class="hljs-type">boolean</span>[] isValid, Deque&lt;<span class="hljs-type">Integer</span>&gt; <span class="hljs-type">path</span>, List&lt;List&lt;<span class="hljs-type">Integer</span>&gt;&gt; res)&#123;<br>    <span class="hljs-keyword">if</span>(depth==nums.length)&#123;<br>        res.<span class="hljs-keyword">add</span>(<span class="hljs-built_in">new</span> ArrayList(<span class="hljs-type">path</span>));<br>        <span class="hljs-keyword">return</span>;<br>    &#125;<br>    <br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i=<span class="hljs-number">0</span>;i&lt;nums.length;i++)&#123;<br>        <span class="hljs-keyword">if</span>(!isValid[i])&#123;<br>            <span class="hljs-type">path</span>.addLast(nums[i]);<br>            isValid[i]=<span class="hljs-keyword">false</span>;<br>            recursion(nums, depth+<span class="hljs-number">1</span>, isValid, <span class="hljs-type">path</span>, res);<br>            isValid[i]=<span class="hljs-keyword">true</span>;<br>            <span class="hljs-type">path</span>.removeLast();<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><ol><li>这个过程中不止涉及一个递归过程，循环的每一个分支都是一个递归过程，每个递归过程中递归到最后直接得到答案，因此每个分支的递归过程都是自顶向下的；</li><li>再看循环过程，循环过程的语义是选择，也就是操作树的分支；</li><li>本题是有分支的递归，两个分支具有相同的原问题，因此本题是自顶向下递归的变种，本质上还是自顶向下的递归；</li></ol></li><li><p>回头考虑156题，根据其问题规模递减的顺序和遍历顺序应该采用自顶向下的递归，因此由当前问题进入下一问题后得到的应该是最终的答案，即采用return recursion(n-1);</p>   <figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">public TreeNode recursion(TreeNode root, TreeNode right)&#123;<br>    <span class="hljs-keyword">if</span>(root==null)<br>     return right;<br>    <br>    TreeNode left=root.right!=null?<span class="hljs-keyword">new</span> <span class="hljs-constructor">TreeNode(<span class="hljs-params">root</span>.<span class="hljs-params">right</span>.<span class="hljs-params">val</span>)</span>:null;<br>    return recursion(root.left, <span class="hljs-keyword">new</span> <span class="hljs-constructor">TreeNode(<span class="hljs-params">root</span>.<span class="hljs-params">right</span>.<span class="hljs-params">val</span>, <span class="hljs-params">left</span>, <span class="hljs-params">right</span>)</span>);<br>&#125;<br></code></pre></td></tr></table></figure><p>   本文中对于递归不同种类的代码形式是重要的，可以帮助我们很快的组织代码；</p></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>Computer Science</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Speculation</title>
    <link href="/2022/04/10/Speculation/"/>
    <url>/2022/04/10/Speculation/</url>
    
    <content type="html"><![CDATA[<ol><li><p>什么是思辨？从一个方形桌子说起。当我们从方桌转向方形的时候，我们已经在试图把方桌概念中的经验性内容——桌子剔除了，剩下的就是作为形的性质的方。</p></li><li><p>当我们进入性质领域——一个比经验领域更加抽象的领域时，我们可以去追问方形和其他形之间的关系，那么就进入了几何学了。</p></li><li><p>但如果我们继续之前的思维方式——继续剔除概念中的经验性的东西，那么我们就会继续对方形进行解构从而试图进入纯粹理性的区域——思辨；</p></li><li><p>方形又是什么呢？由四条相等的线段组成的封闭的平面图形。</p></li><li><p>如果以(4)中的定义来展开分析就会得到下面的方形的本质中的因素：</p><ol><li>作为我们空间观念表达方式的抽象线条；</li><li>抽象线条的可度量性和以此为根据的可判等性；</li></ol></li><li><p>根据(5)中的结论我们可以继续追问：我们的空间观念中又包含了哪些经验性因素呢？抽象线条的可度量性的根据又从哪里来呢？</p></li><li><p>对于(6)中的追问我目前没有能力回答，因此暂时断言空间观念和空间的可度量性来源于理性的规定，即这些都是理性的组成部分；</p></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>Speculation</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Galois Theroy(1)</title>
    <link href="/2022/04/08/Galois-Theroy/"/>
    <url>/2022/04/08/Galois-Theroy/</url>
    
    <content type="html"><![CDATA[<ol><li><p>什么是对称？</p><p>为了获得这种艾多斯，我们从几个例子进行直观：</p><ul><li>正方形是对称的；</li><li>物理定律是对称的；</li><li>多项式方程根的加法和乘法的结果是对称的；</li></ul><p>对称就是“基于某种操作下的不变性”。</p><ol><li>正方形绕中心点旋转90度、180度、270度、360度是不变的，因此我们叫这种对称为中心对称。正方形沿对角线对折可以重合，这可以等价为正方形绕对角线旋转180度、360度是不变的。同样的绕着中垂线旋转正方形也是不变的。</li><li>从(i)中可知，正方形的三种对称的唯一区别就是三组操作不同：<code>&#123;“绕中心点旋转n* 90度”，“绕对角线旋转n* 180度”，“绕着中垂线旋转n* 180度”&#125;</code>对此我们可以进一步还原——将正方形换成长宽相等的十字架、圆等形状同等操作下的对称性仍然成立，根据胡塞尔的本质还原理论，我们可以进一步将形状从对称的本质领域剔除，因此还原得到的对称的本质就只剩下“操作”了。</li><li>根据(ii)中的结论，是“操作”使某一种对称成为了那种对称。在此基础上我们继续看物理定律的对称，物理定律从古到今是不变的，因此物理定律的对称是基于时间的对称。历史在现在及未来是不变的，因此历史基于现在及未来的时间是对称的；</li></ol></li><li><p>对称的数学表示</p><ul><li>我们要描述的是某一种对称的本质，根据(1)中的结论，我们要描述的就是某一种“操作”，那么接下来我们进一步对“操作”进行分析；</li><li>我们还是用一个例子进行直观，那(1)中的(ii)中集合的第一个元素“绕中心点旋转n* 90度”进行分析；</li><li>这个操作包含了两部分：一个动作“绕中心点旋转”+动作的量n*90度；</li><li>“绕中心点旋转”是共同部分，但由于剔除这部分会导致无法识别对称，因此我们要保留这部分语义，而第二部分由于涉及量，我们就可以定义运算；</li><li>于是我们得到这样一种表达：0表示绕中心点旋转0度，r表示绕中心点旋转90度，2r表示绕中心点旋转180度，3r表示270度递增，由此我们得到一个操作集合<code>G=&#123;0, r, 2r, 3r&#125;</code>并且我们发现当旋转270度后再旋转90度又相当于旋转了0度；</li><li>而基于这个集合可以发现不同操作的量之间是加法关系，因此定义的运算为抽象的加法；</li><li>同理我们还可以得到另一种操作集合<code>H=&#123;1, r, r^2, r^3&#125;</code>，那么基于这个集合操作的量之间的关系，我们定义抽象乘法操作；</li></ul></li><li><p>群的定义</p><ol><li><p>根据(2)的结论，对于对称的描述需要一个操作集合和一个基于这个集合的运算，我们把这两部分合起来用字母定义就得到了群；</p></li><li><p>假设操作集合用G表示，抽象运算用  ·表示，那么(G, ·)就表示一个对称；</p></li><li><p>由(2)知，这个对称还有如下性质：</p><ul><li>G中的任意两个元素做·运算得到的元素必还存在于G中——封闭性；</li><li>G中的三个元素做·运算满足结合律；</li><li>存在一个单位元e，它和任意元素做运算都会得到这个元素自身；</li><li>任何一个元素都存在逆元，即a·b&#x3D;e，a和b互为逆元；</li></ul></li><li><p>我们把满足上面四条的(G, ·)成为群；</p></li></ol></li><li><p>群的同构</p><ol><li>从(2)中对正方形中心对称的两种表达，即(G, +)和(H, *)开看，虽然集合的内容和定义的运算不同，但他们却有着相同的内涵——同一种结构的对称，可知这两个群是具有某种同一性的，我们称之为同构；</li></ol></li><li><p>多项式方程根的加法和乘法结果的对称</p><ul><li>我们那一元二次方程ax^2+bx+c&#x3D;0来就来举例，根据韦达定理我们知道x1+x2&#x3D;-b&#x2F;a, x1*x2&#x3D;c&#x2F;a;</li><li>由此我们得到了这个一元二次方程的根的加法和乘法在互换加数和乘数的情况下结果是不变的，即x2+x1&#x3D;x1+x2, x1<em>x2&#x3D;x2</em>x1；</li><li>并且我们还可以进一步排除方程具体性的影响，即换一个方程上面的等式还成立，由此我们就得到了一元二次方程加法和乘法结果的对称，这种对称的本质是“互换”操作；</li><li>我们把这个对称表达出来，就是<code>G=&#123;0, r&#125;</code>分别表示互换0次，互换1次，互换两次又回到了0次，因此定义的运算是加法，我们得到了一个群(G, +);</li><li>这个群就是著名的伽罗瓦群，关于伽罗瓦理论的提出和具体内容见下一篇；</li></ul></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>Mathematics</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2022/04/08/hello-world/"/>
    <url>/2022/04/08/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
