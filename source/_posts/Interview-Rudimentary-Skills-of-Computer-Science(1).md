---
title: Rudimentary Skills of Computer Science
date: 2022-04-20 04:23:08
tags: Computer Science
---
1. GC过程：
   1. JVM将堆内存分为两部分：
      1. 新生代：分为伊甸园—幸存区From—To；
      2. 老年代；
   2. 伊甸园满了——Minor GC采用复制算法把存活对象放入To中，幸存对象寿命+1，清空伊甸园，From和To互换；
   3. 伊甸园又满了——把伊甸园和From中的对象都放到To中，再清空伊甸园和From，From和To互换；
   4. 又来个对象，把新生代回收完也放不下了，老年代也放不下，触发Full GC，从新生代到老年代都要回收。
   5. Minor GC会触发Stop the World，暂停用户线程；
   6. 寿命保存在对象头中，用4bits表示，因此最大寿命是15；
   7. 大对象直接晋升到老年代；
   8. 一个线程内的outOfMemory不一定会使Java线程结束；
2. 创建线程的方式：
   1. 继承Thread类并重写run方法；
   2. 实现Runnable接口并重写run方法；
   3. 实现Callable接口并实现call()方法，使用FutureTask类来包装Callable对象；
3. 创建线程池的方式：
   1. 线程池的好处：
      1. 关键词：减少——时间、系统资源占用——资源不足——大量同类线程——内存——过渡切换。
      2. 线程池的好处在于可以减少创建和销毁线程所需要的时间和系统资源的开销，解决资源不足的问题。如果不使用线程池，有可能造成系统创建大量同类线程而导致消耗完内存或者“过渡切换”的问题。
   2. Executors创建线程池，由于底层的阻塞队列使用的是LinkedBlockQueue实现的，而LinkedBlockQueue的最大长度为Integer.MAX_VALUE，当我们不设置线程池容量时就意味着可以添加如此多的任务而导致OutOfMemory——可以使用ThreadPoolExecutor来指定BlockQueue的容量。
   3. Executors创建线程的四种方式：
      1. newCachedThreadPool：可缓存线程池，线程池无限大。
      2. newFixedThreadPool：定长线程池，可控制最大并发数，超出的线程会在队列中等待。
      3. newScheduledThreadPool：定长线程池，支持定时及周期性任务执行。
      4. newSingleThreadPool：单线程化的线程池，它会用唯一的工作线程来执行任务，保证所有任务按照指定优先级来执行。
4. TCP四次回收中closewait和timewait的作用：
   1. closewait是服务器在告诉客户端自己成功接收到释放连接的请求后，由于自己还可能有一些数据没有传送完成而进入的状态。
   2. timewait是客户端在告诉服务器自己成功接收到服务器释放连接的请求后，考虑到由于客户端确认报文丢失而引起服务器超时重传，如果此时客户端已经关闭，就会用RST包来响应服务器，这会让服务器认为有错误发生。
   3. timewait的问题：在高并发短连接的情况下，服务器可能会有多个连接处于timewait状态，这有可能会导致连接占用的文件描述符达到上限而无法继续建立正常连接。
5. cookie和session有哪些区别？
   1. cookie是保存在浏览器端的用于保存用户信息的数据，会在浏览器向服务器发送请求时被携带发送在服务器上。通常它用于告知服务端两个请求是否来自同一浏览器，通常有以下三方面用途：
      1. 回话状态管理：用户登录状态、购物车、游戏分数或者其他需要记录的信息。
      2. 个性化信息：用户自定义设置、主题等等。
      3. 浏览器行为跟踪：跟踪分析用户行为等。
   2. session代表着服务器和客户端一次回话的过程，session对象存储特定用户会话所需要的属性及配置信息。这样，当用户在应用程序的web页之间跳转时，存储在session对象中的变量不会消失。当浏览器关闭会话或者session超时失效时会话结束。
   3. cookie和session的区别：
      1. 作用范围不同：cookie保存在客户端，session保存在服务端；
      2. 存取方式不同：cookie只能保存ASCII码，session可以保存任意的数据类型。
      3. 有效期不同：cookie可以设置为长时间保持，比如我们经常使用的默认登录功能，session一般失效时间较短，客户端关闭或者session超时都会失效。
      4. 隐私策略不同：cookie存储在客户端容易遭到不法窃取，session存储在服务端安全性好一些；
      5. 存储大小不同：单个cookie保存的数据不能超过4K，session可以存储的数据远高于cookie；
   4. 为什么需要cookie和session，他们有什么关联？
      1. 浏览器使用的HTTP协议的无状态性导致浏览器不知道正在使用他们的是谁，通过cookie和session的配合可以告诉服务器本次操作的用户是否登录、是哪个用户在操作。
      2. cookie和session的配合流程：
         1. 用户第一次请求服务器的时候，服务器根据用户提交的信息，创建对应的session，请求返回时将此session的唯一标识信息SessionID返回给客户端，客户端接收后将此信息存储在cookie中并同时记录此SessionID所属的域名。
         2. 用户第二次访问服务器的时候，请求会自动判断此域名是否存在cookie信息，如果存在会将cookie发送给服务端，服务端从中获取SessionID，据此查找相应的session，如果没有证明用户没登录或登录失败，找到则说明用户已登录并且可移执行后续操作。
   5. 如果浏览器禁止cookie，那么怎么保障整个机制的正常运转？
      1. 第一种方案可以在请求后携带SessionID参数；
      2. 第二种方案可以采用Token机制。Token是服务端生成的一个字符串作为客户端请求的标识，第一次用户登录后服务器产生一个Token交给客户端，以后的每次请求都携带这个Token就好而无需再次登录验证。
   6. 分布式session问题，多台服务器共同支撑前端用户请求，用户两次访问服务端连接到的是不同的服务器，那么session怎么保证有效？
      1. 可以将每个请求按照访问IP的hash分类，这样来自同一IP固定访问一个服务器。
      2. session复制：当一个服务器的session改变之后，该节点会将session序列化广播给所有服务器。
      3. 共享session：服务端无状态化，将用户的session等信息采用缓存中间件统一管理。
6. Java中的锁有哪些？
7. ReentrantLock和synchronized有什么区别？
8. ConcurrentHashMap是怎么保证线程安全的？
9.  mysql索引的最左匹配：
10. mysql事务：
11. mysql什么情况下会加锁？
12. select语句没有走索引，有哪些原因？
13. 动态代理的实现？
14. 深拷贝与浅拷贝：
15. Java中volatile关键字：
    1.  变量的可见性保证：两个线程分别在不同的核中运行时会把内存中的共享变量读取到各自的cache中，因此某个线程改变变量之后由于cache写策略的不同可能导致另一线程对于本线程的更改不可见，因此会使用volatile关键字保证变量可见性。
        1. 在读取volatile变量时，线程中所有在volatile之后的变量都会重新从内存中读取到cache，而volatile之前的变量由于没有解释器没有检查到volatile关键字因此还是从cache中读取，可能不是最新值；
        2. 在写入volatile变量时，线程中所有在volatile之前的变量都会从cache写入内存，而volatile之后的变量由于解释器没有检测到这个关键字，因此不会故意触发写直达的策略；
     1. happens-before保证：指令重排的情况下，happens-before原则保证以下两点：
        1. 排在volatile之前的写指令不能重排序到volatile之后；
        2. 排在volatile之后的读指令不能重排序到volatile之前；
     2. 综上所述，volatile关键字提供的是读写原则：
        1. 从volatile开始的所有读都是从内存读而不是从cache读；
        2. 发现volatile关键字需要写变量时将cache中的内容更新到内存中；
        3. 在这两个原则的基础上可以实现上述两个功能；
     3. cache的读写策略的转换应该是操作系统层面的功能，JVM应该是调用了操作系统的接口来实现一下的功能：
        1. 不从cache读而从内存读，读完更新cache；
        2. 将cache的内容写入内存；
16. volatile进阶：
    1.  volatile实现：反汇编可知，volatile的汇编代码中加了lock前缀，查询IA-32手册可知lock前缀的功能：
        1. 在修改内存操作时，使用LOCK前缀去调用加锁的读-修改-写操作，这种机制用于多处理器系统中处理器之间进行可靠的通讯，具体描述如下：
           1. 在Pentium和早期的IA-32处理器中，LOCK前缀会使处理器执行当前指令时产生一个LOCK#信号，这种总是引起显式总线锁定出现；
           2. 在Pentium4、Inter Xeon和P6系列处理器中，加锁操作是由高速缓存锁或总线锁来处理。如果内存访问有高速缓存且只影响一个单独的高速缓存行，那么操作中就会调用高速缓存锁，而系统总线和系统内存中的实际区域内不会被锁定。同时，这条总线上的其它Pentium4、Intel Xeon或者P6系列处理器就回写所有已修改的数据并使它们的高速缓存失效，以保证系统内存的一致性。如果内存访问没有高速缓存且/或它跨越了高速缓存行的边界，那么这个处理器就会产生LOCK#信号，并在锁定操作期间不会响应总线控制请求
        2. IA-32架构提供了几种机制用来强化或弱化内存排序模型，以处理特殊的编程情形。这些机制包括：
           1. I/O指令、加锁指令、LOCK前缀以及串行化指令等，强制在处理器上进行较强的排序
           2. SFENCE指令（在Pentium III中引入）和LFENCE指令、MFENCE指令（在Pentium4和Intel Xeon处理器中引入）提供了某些特殊类型内存操作的排序和串行化功能
           3. 这些机制可以通过下面的方式使用：总线上的内存映射设备和其它I/O设备通常对向它们缓冲区写操作的顺序很敏感，I/O指令（IN指令和OUT指令）以下面的方式对这种访问执行强写操作的排序。在执行了一条I/O指令之前，处理器等待之前的所有指令执行完毕以及所有的缓冲区都被都被写入了内存。只有取指令和页表查询能够越过I/O指令，后续指令要等到I/O指令执行完毕才开始执行。
        3. 缓存锁：缓存锁定是某个CPU对缓存数据进行更改时，会通知缓存了该数据的CPU抛弃缓存的数据或者从内存重新读取。
        4. 两种不能使用缓存锁的情况：
           1. 第一种情况是操作的数据不能被缓存在处理器内部，或者操作的数据跨多个缓存行（cache line）时，则处理器会调用总线锁定——由此可知为什么对象的内存结构中必须有对齐从而避免加载入缓存时跨多个数据行了，除了有效率的考虑外还有就是加缓存锁的保证；
           2. 第二种情况是处理器不支持缓存锁定，对于Intel 486和Pentium处理器，就算锁定的内存区域在处理器的缓存行中也会调用总线锁定。
     1. 过程：工作内存Work Memory其实就是对CPU寄存器和高速缓存的抽象，或者说每个线程的工作内存也可以简单理解为CPU寄存器和高速缓存。
        1. 那么当写两条线程Thread-A与Threab-B同时操作主存中的一个volatile变量i时，Thread-A写了变量i，那么
           1. Thread-A发出LOCK#指令
           2. 发出的LOCK#指令锁总线（或锁缓存行），同时让Thread-B高速缓存中的缓存行内容失效
           3. Thread-A向主存回写最新修改的i
           4. Thread-B读取变量i，那么：
        2. Thread-B发现对应地址的缓存行被锁了，等待锁的释放，缓存一致性协议会保证它读取到最新的值
           1. 由此可以看出，volatile关键字的读和普通变量的读取相比基本没差别，差别主要还是在变量的写操作上。
17. Java序列化机制：
     1. 将对象转化为字节流存储在磁盘用于网络运输或者独立于进程保存；
     2. 可以实现Serializable接口，用ObjectOutputStream类的writeObject方法序列化，但是这个类中的成员必须也是可序列化的；
     3. 序列化是不会将同一个对象重复序列化；
     4. 可以使用transient关键字修饰那些可序列化类中不想序列化的对象；
18. https对称加密和非对称加密的详细过程：
    1.  对称加密：加密和解密用一把钥匙，对称加密如果秘钥被劫持会导致信息不安全；
    2.  非对称加密：用公钥加密的信息需要私钥解开，用私钥加密的信息需要公钥解开，非对称加密中一方保存私钥，发送公钥，则即使公钥被劫持也只能解密由私钥加密的传输信息而无法解密由公钥加密的传输信息——非对称加密可以保证单个方向传输的安全性；
    3.  由于非对称加密可以保证单方向传输的安全性，可以采用非对称加密从浏览器向服务器传输加密的对称秘钥——服务器将公钥明文传输给浏览器，浏览器生成对称秘钥，用公钥加密后传送给服务器，此时即使被劫持也无法获取到秘钥。然后两方用这个秘钥加密信息进行通信。
    4.  中间人攻击：劫持服务器发送给浏览器的公钥A，替换为公钥B发送给浏览器，浏览器用公钥B加密对称秘钥X之后，中间人就可以用私钥B`解密得到X，再将X用公钥A加密发送给浏览器，如此中间人就获得了对称秘钥X；
    5.  数字证书：网站在使用HTTPS之前需要向CA机构申领一份数字证书，数字证书中含有证书持有者信息。公钥信息等，服务器会把证书传送给浏览器，浏览器从证书中获取公钥。
    6.  如何防止数字证书被篡改？
        1.  运用数字签名：
            1.  服务端用数据生成散列值并用自己的私钥加密形成签名附加到数据之后，由于运用的是私钥因此中间人无法改变数据后重新生成签名。
            2.  浏览器用公钥解密签名得到散列值并自己用数据生成散列值查看二者是否相同，一致则数字签名有效。
        2. 中间人不可能掉包证书：由(1)知中间无法更改证书内容，因此如果掉包，那么浏览器只需要对比证书上的域名和自己申请访问的域名就知道证书有没有被掉包了。 
19. HTTP三次握手就是TCP三次握手；
20. 输入URL后浏览器响应的过程：
    1.  输入地址：浏览器在历史记录、书签等地方搜索到已输入字符串可能对应的URL，然后提示补全。Chrome浏览器甚至会从缓存中把网页展示出来，此时我们还没有回车，网页就展示出来了。
    2.  请求发起后，浏览器需要解析域名，如果本地hosts文件没有找到对应的IP地址，浏览器就会发送DNS请求到本地DNS服务器——一般是ISP，比如中国电信、中国移动等；
    3.  本地DNS服务器首先查询缓存，如果有这条记录就直接返回结果，这个过程是递归式查询。如果没有记录就询问DNS根服务器；
    4.  根服务器没有的话就会告诉本地DNS服务器去域服务器上查询，并给出地址，这个过程是迭代的；
    5.  本地DNS向域服务器发出请求，域服务器告诉本地DNS服务器它所请求的域名的解析服务器的地址；
    6.  本地DNS服务器向解析服务器发送请求，获得IP地址，然后将此地址返回给浏览器，并保存在自己的缓存中；
    7.  浏览器会以一个随机端口向服务器的80端口发送TCP连接请求，这个请求到达服务器进入网卡，进入TCP/IP协议栈、防火墙最终进入WEB程序，处理请求。 
21. TCP拥塞控制：
    1.  慢开始——由于一开始不知道网络的负荷情况，为了避免大量的数据字节传送进网络，因此采用从小到大增加拥塞窗口的策略，即从1开始每次乘2；
    2.  拥塞避免——当窗口大小达到阈值之后采用线性增长。当达到拥塞时，此时将新的慢开始的阈值变为此时窗口值的一半，并将窗口重新变为1。  
22. TCP流量控制：
23. InnoDB特性，B树和B+树的区别：
24. 乐观锁和悲观锁：
    1.  悲观锁：每次更新数据时都会认为别人会抢占数据进行更改；
    2.  乐观锁：访问数据认为不会有人抢占数据，等到更新的时候再判断这个数据是否被更改；
25. mysql主从复制：
26. HTTP中POST和GET的区别：
27. 自旋锁和互斥锁有什么区别？
28. String、StringBuffer和StringBuilder之间的区别？
29. TCP/IP参考模型：
    1.  应用层：OSI参考模型中的会话层、表示层、应用层功能合并到应用层实现，协议有FTP、Telnet、DNS、SMTP、HTTP等；
    2.  传输层：TCP、UDP；
    3.  网络互联层：网络层，IP、IGMP、ICMP；
    4.  网络接入层：对应于OSI的物理层和链路层。TCP/IP并未真正描述这一层，而是由参与互联的各网络使用自己的物理层和链路层协议，然后与TCP/IP的网络接入层连接；
30. Java中的反射机制：
31. 进程和线程的区别：
    1.  进程是操作系统分配资源的最小单位；
    2.  线程是进程的一部分，描述指令流执行状态。它是进程中指令执行流的最小单元，是CPU调度的最小单位；
    3.  线程=进程-共享资源（代码段、数据段、打开文件）
    4.  进程拥有一个完整的资源平台而线程只独享指令流执行的必要资源如寄存器和栈；
    5.  线程能够减少并发执行的时间和空间开销
        1.  线程的创建和销毁比进程需要的时间短；
        2.  同一进程内线程的切换比进程短；
        3.  由于同一进程内各线程间共享内存和文件资源，可以不通过内核进行直接通信；
32. 进程通信的方式：
    1.  直接通信：两个进程之间建立一对一的链路；
    2.  间接通信：通过操作系统维护的消息队列实现进程间的消息接收和发送；
        1.  每个消息队列都有一个唯一标识；
        2.  只有共享了相同消息队列的进程才能通信；
    3. 几种具体的实现方式：
       1. 信号：进程之间的软中断通知和处理机制；
       2. 管道：进程间基于内存文件的通信机制；
       3. 消息队列；
       4. 共享内存：把同一个物理内存区域同时映射到多个进程的内存地址空间；
33. Telnet协议：
34. 虚拟内存：
35. 内核态和用户态解释一下：
36. Map的遍历方式：
    1. 把容量设置为2^n这样可以将取余操作转化为按位与操作提高效率（key%M=key&&(M-1)），但是由于这相当于截取key末尾的n个比特（即低位掩码）而导致key的高位比特对于哈希值没有影响，因此很大程度上降低了散列的随机性和均匀性。
    2. 为了改善c中对于随机性和均匀性的降低， Java采用hashcode的高16位和低16位异或，这样使得高位也能影响散列值，能降低hash碰撞；  
    3. 1.8开始扩容之后不用重新hash而是直接定位原节点在新数组的位置，因为数组容量扩大2倍无非就是高位多了一个1，那如果原来数据的hashcode的高位为1则重hash的值比原来大了一个旧数组的容量，为0则没变；
37. Java线程阻塞的情况：
    1.  线程休眠：sleep方法放弃CPU使用权，但不放弃锁；
    2.  线程等待获取锁才能进行下一步操作；
    3.  线程执行wait进入阻塞状态；
    4.  等待相关资源；
    5.  请求连接时；
    6.  读取线程等待数据；
    7.  线程写数据时可能会出现；
